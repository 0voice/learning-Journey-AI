# ğŸš€ğŸš€ğŸš€ AI Learning Hub Â· 2025 æœ€å¼º AI å­¦ä¹ è·¯çº¿ï¼Œä»å…¥é—¨åˆ°å®æˆ˜ï¼Œå…¨æµç¨‹è‡ªå­¦æŒ‡å—

<p align="center">
  <img src="Image2.jpg" alt="2025 AI Learning Banner" width="100%">
</p>

---

> **æŒæ¡ AIï¼Œä»è¿™é‡Œå¼€å§‹**  
> ä¸ºæ‰€æœ‰å¯¹ AI çŸ¥è¯†æ„Ÿå…´è¶£çš„å­¦ä¹ è€…æ‰“é€ çš„ AI / ML / DL ç³»ç»Ÿå­¦ä¹ è·¯çº¿ï¼Œæ¶µç›–ä¼˜è´¨è¯¾ç¨‹ã€ç»å…¸ä¹¦ç±ã€èåˆé¡¶çº§èµ„æºã€ä»£ç å®æˆ˜ä¸å¼€æºå·¥å…·ï¼Œä¸ºä½ æ‰“é€ ä»å…¥é—¨åˆ°å®æˆ˜å†åˆ°å‰æ²¿ç ”ç©¶çš„ AI æˆé•¿ä¹‹è·¯ã€‚  
>> **ç»“æ„åŒ– | æŒç»­æ›´æ–° | æœ€æ–°å­¦ä¹  |ç¤¾åŒºå…±å»º** [![GitHub Stars](https://img.shields.io/github/stars/0voice/learning-Journey-AI?style=social)](https://github.com/0voice/learning-Journey-AI)

---

**ğŸ¯ é€‚åˆå¯¹è±¡**ï¼š  
- æƒ³ä»é›¶èµ·æ­¥å­¦ä¹  AI çš„å¼€å‘è€…  
- éœ€è¦ä¸€æ¡ç³»ç»Ÿã€å¯è½åœ°çš„å­¦ä¹ è·¯å¾„çš„å­¦ä¹ è€…  
- å…³æ³¨è¡Œä¸šä¸€çº¿è¿›å±•ï¼Œæƒ³æŒæ¡å‰æ²¿æŠ€æœ¯çš„äºº

ğŸŒŸ **ä½ å°†è·å¾—**ï¼š  
âœ… æ¸…æ™°çš„é˜¶æ®µæ€§å­¦ä¹ è·¯çº¿å›¾  
âœ… ç²¾é€‰é«˜è´¨é‡å­¦ä¹ èµ„æºä¸å·¥å…·  
âœ… è¦†ç›–ä»åŸºç¡€åˆ°è¿›é˜¶çš„å®æˆ˜é¡¹ç›®  
âœ… å®šæœŸæ›´æ–°ï¼Œèšç„¦ä¸»æµä¸å‰æ²¿  
âœ… æ¬¢è¿å¼€æºç¤¾åŒºå…±åŒå»ºè®¾


**ğŸ” å¿«é€Ÿå…¥å£**

| æˆ‘æ˜¯...  | å¿«é€Ÿå…¥å£                                                         |
| ------ | ------------------------------------------------------------ |
| åˆå­¦è€…    | [ğŸ“˜ Python å¿«é€Ÿå…¥é—¨](https://github.com/0voice/learning-Journey-AI/tree/main/Python%20and%20Math) |
| æœ‰åŸºç¡€è€…   | [ğŸ“˜ æœºå™¨å­¦ä¹ æ ¸å¿ƒæ¦‚å¿µ](https://github.com/0voice/learning-Journey-AI/tree/main/Machine%20Learning)                 |
| æƒ³ç›´æ¥åšé¡¹ç›® | [ğŸ”§ å®æˆ˜é¡¹ç›®é›†](https://github.com/pytorch/examples)                         |
| ç ”ç©¶çˆ±å¥½è€…  | [ğŸ“˜ è®ºæ–‡ç²¾è¯»æŒ‡å—](https://github.com/terryum/awesome-deep-learning-papers)           |


**âœˆï¸ å­¦ä¹ è·¯çº¿å›¾ Overview**

```mermaid
flowchart TD
    A[ç¼–ç¨‹åŸºç¡€Python] --> B[æ•°å­¦åŸºç¡€]
    B --> C[æœºå™¨å­¦ä¹ ]
    C --> D[æ·±åº¦å­¦ä¹ åŸºç¡€]
    D --> E[è®¡ç®—æœºè§†è§‰]
    D --> F[è‡ªç„¶è¯­è¨€å¤„ç†]
    D --> G[ç”Ÿæˆå¼AI]
    C --> H[å·¥å…·é“¾å®è·µ]
    H --> I[éƒ¨ç½²ä¸MLOps]
    E & F & G --> J[ä¸“é¡¹é¡¹ç›®å®æˆ˜]
    style A fill:#4CAF50,stroke:#388E3C
```

# ***ğŸ“š å­¦ä¹ è·¯å¾„åˆ†é˜¶æ®µ***
* [é˜¶æ®µ 0ï¼šå‰ç½®çŸ¥è¯†](#1)

* [é˜¶æ®µ 1ï¼šæœºå™¨å­¦ä¹ ](#2)

* [é˜¶æ®µ 2ï¼šæ·±åº¦å­¦ä¹ ](#3)  

* [é˜¶æ®µ 3ï¼šå·¥å…·ä¸å®è·µ](#4)

> ğŸ’¡**ä¸å†ä¿¡æ¯è¿‡è½½ï¼Œä¸å†æ— ä»ä¸‹æ‰‹ï¼Œä»è¿™é‡Œå¼€å§‹ç³»ç»ŸæŒæ¡ AIã€‚**

---

# **<h3 id="1">[ğŸ¯ é˜¶æ®µ 0ï¼šå‰ç½®çŸ¥è¯† æ•°å­¦åŸºç¡€](Python%20and%20Math)</h3>**
## [Pythonå…¥é—¨åŸºç¡€ï¼šé›¶åŸºç¡€å°ç™½å­¦ä¹ æŒ‡å—](Python%20and%20Math/python.md)


### 1.å˜é‡ä¸æ•°æ®ç±»å‹
å˜é‡å°±åƒç”Ÿæ´»ä¸­çš„â€œæ ‡ç­¾â€ï¼Œç»™æ•°æ®èµ·åå­—æ–¹ä¾¿ä½¿ç”¨ï¼š
```python
# åˆ›å»ºå˜é‡
name = "å°æ˜"        # å­—ç¬¦ä¸² (æ–‡å­—)
age = 20             # æ•´æ•° (æ•°å­—)
height = 1.75        # æµ®ç‚¹æ•° (å¸¦å°æ•°ç‚¹çš„æ•°å­—)
is_student = True    # å¸ƒå°”å€¼ (çœŸ/å‡)

print(name)          # è¾“å‡º: å°æ˜
print(age + 5)       # è¾“å‡º: 25
```

### 2.æ§åˆ¶ç»“æ„ï¼šæ¡ä»¶åˆ¤æ–­
å¦‚æœ...é‚£ä¹ˆ...å¦åˆ™...çš„é€»è¾‘ï¼š
```python
# æ¡ä»¶åˆ¤æ–­ç¤ºä¾‹
temperature = 28

if temperature > 30:
    print("å¤ªçƒ­äº†ï¼å¼€ç©ºè°ƒ")
elif temperature > 20:
    print("å¤©æ°”çœŸèˆ’æœ")
else:
    print("æœ‰ç‚¹å†·ï¼Œå¤šç©¿ç‚¹")
```

### 3.æ§åˆ¶ç»“æ„ï¼šå¾ªç¯
é‡å¤æ‰§è¡ŒæŸäº›æ“ä½œï¼š
```python
# forå¾ªç¯ç¤ºä¾‹ - éå†åºåˆ—
fruits = ["è‹¹æœ", "é¦™è•‰", "æ©™å­"]

for fruit in fruits:
    print(f"æˆ‘çˆ±åƒ{fruit}")

# whileå¾ªç¯ç¤ºä¾‹ - è¾¾åˆ°æ¡ä»¶å‰é‡å¤
count = 0
while count < 5:
    print(f"è¿™æ˜¯ç¬¬{count+1}æ¬¡è¯´ä½ å¥½")
    count += 1
```

### 4. å‡½æ•°å®šä¹‰ä¸è°ƒç”¨
æŠŠå¸¸ç”¨æ“ä½œæ‰“åŒ…æˆ"å·¥å…·"ï¼š
```python
# å®šä¹‰å‡½æ•°ï¼šè®¡ç®—åœ†çš„é¢ç§¯
def circle_area(radius):
    area = 3.14 * radius * radius
    return area

# ä½¿ç”¨å‡½æ•°
print(circle_area(5))  # è®¡ç®—åŠå¾„ä¸º5çš„åœ†é¢ç§¯
```
### 5. ç±»ä¸é¢å‘å¯¹è±¡ç¼–ç¨‹
åˆ›å»ºè‡ªå®šä¹‰çš„æ•°æ®ç±»å‹ï¼š
```python
# å®šä¹‰"æ±½è½¦"ç±»
class Car:
    # åˆå§‹åŒ–æ–¹æ³•(ç»™æ–°è½¦è®¾ç½®å±æ€§)
    def __init__(self, brand, color):
        self.brand = brand
        self.color = color
    
    # ç±»çš„æ–¹æ³•(è¡Œä¸º)
    def drive(self):
        print(f"{self.color}è‰²çš„{self.brand}æ­£åœ¨è¡Œé©¶")

# ä½¿ç”¨ç±»åˆ›å»ºå¯¹è±¡
my_car = Car("ç‰¹æ–¯æ‹‰", "é»‘")
my_car.drive()  # è¾“å‡º: é»‘è‰²çš„ç‰¹æ–¯æ‹‰æ­£åœ¨è¡Œé©¶
```

### 6. å¼‚å¸¸å¤„ç†
é˜²æ­¢ç¨‹åºå‡ºé”™æ—¶å´©æºƒï¼š
```python
# å°è¯•æ‰“å¼€ä¸€ä¸ªä¸å­˜åœ¨çš„æ–‡ä»¶
try:
    file = open("ä¸å­˜åœ¨çš„æ–‡ä»¶.txt", "r")
except FileNotFoundError:
    print("æ‰¾ä¸åˆ°æ–‡ä»¶ï¼è¯·æ£€æŸ¥æ–‡ä»¶å")
```

## æ•°æ®ç»“æ„åŸºç¡€

### 1.åˆ—è¡¨/å…ƒç»„/å­—å…¸/é›†åˆ

| ç±»å‹   | ç‰¹ç‚¹                 | ç¤ºä¾‹                                 |
|--------|----------------------|--------------------------------------|
| åˆ—è¡¨   | å¯ä¿®æ”¹çš„æœ‰åºé›†åˆ     | `fruits = ["è‹¹æœ", "é¦™è•‰", "æ©™å­"]`  |
| å…ƒç»„   | ä¸å¯ä¿®æ”¹çš„æœ‰åºé›†åˆ   | `point = (3, 5)`                     |
| å­—å…¸   | é”®å€¼å¯¹é›†åˆ           | `student = {"å§“å": "å°æ˜", "å¹´é¾„": 20}` |
| é›†åˆ   | æ— é‡å¤å…ƒç´ çš„æ— åºé›†   | `unique_numbers = {1, 2, 3, 2} â†’ {1, 2, 3}` |

```python
# ç»¼åˆç¤ºä¾‹
# è´­ç‰©æ¸…å•ï¼ˆåˆ—è¡¨ï¼‰
shopping_list = ["ç‰›å¥¶", "é¸¡è›‹", "é¢åŒ…"]

# å•†å“ä»·æ ¼ï¼ˆå­—å…¸ï¼‰
prices = {
    "ç‰›å¥¶": 15.5,
    "é¸¡è›‹": 12.8,
    "é¢åŒ…": 8.0
}

# è®¡ç®—æ€»ä»·
total = 0
for item in shopping_list:
    if item in prices:
        total += prices[item]

print(f"è´­ç‰©æ€»ä»·: {total}å…ƒ")  # è¾“å‡º: è´­ç‰©æ€»ä»·: 36.3å…ƒ
```

### 2.æ ˆä¸é˜Ÿåˆ—
ä¸¤ç§æ•°æ®æ“ä½œæ–¹å¼ï¼š
- â€‹â€‹æ ˆï¼ˆStackï¼‰â€‹â€‹ï¼šåè¿›å…ˆå‡ºï¼ˆLIFOï¼‰ï¼Œåƒå ç›˜å­
```python
# ä½¿ç”¨åˆ—è¡¨å®ç°æ ˆ
stack = []
stack.append("ç¬¬1ç›˜")  # æ”¾å…¥
stack.append("ç¬¬2ç›˜")
top = stack.pop()      # å–å‡º: "ç¬¬2ç›˜"
```
- â€‹â€‹é˜Ÿåˆ—ï¼ˆQueueï¼‰â€‹â€‹ï¼šå…ˆè¿›å…ˆå‡ºï¼ˆFIFOï¼‰ï¼Œåƒæ’é˜Ÿ
```python
# ä½¿ç”¨é˜Ÿåˆ—
from collections import deque
queue = deque()
queue.append("ç¬¬1äºº")  # æ’é˜Ÿ
queue.append("ç¬¬2äºº")
first = queue.popleft()  # æœåŠ¡: "ç¬¬1äºº"
```

### 3. é“¾è¡¨/æ ‘/å›¾
å¸¸ç”¨æ•°æ®ç»“æ„å¯è§†åŒ–æ¯”è¾ƒï¼š

```mermaid
graph TD
    A[æ•°æ®ç»“æ„] --> B[çº¿æ€§]
    A --> C[éçº¿æ€§]
    
    B --> D[é“¾è¡¨]
    D --> D1[å•å‘é“¾è¡¨]
    D --> D2[åŒå‘é“¾è¡¨]
    
    C --> E[æ ‘]
    E --> E1[äºŒå‰æ ‘]
    E --> E2[å¹³è¡¡æ ‘]
    
    C --> F[å›¾]
    F --> F1[æœ‰å‘å›¾]
    F --> F2[æ— å‘å›¾]
```

å®é™…åº”ç”¨ï¼š
- â€‹â€‹é“¾è¡¨â€‹â€‹ï¼šæµè§ˆå™¨å†å²è®°å½•
- æ ‘â€‹â€‹ï¼šæ–‡ä»¶ç³»ç»Ÿç»„ç»‡
- å›¾â€‹â€‹ï¼šç¤¾äº¤ç½‘ç»œå…³ç³»

### 4. æ—¶é—´/ç©ºé—´å¤æ‚åº¦åˆ†æ
è¯„ä¼°ç®—æ³•æ•ˆç‡çš„æ–¹æ³•ï¼š
- æ—¶é—´å¤æ‚åº¦â€‹â€‹ï¼šç®—æ³•è¿è¡Œæ—¶é—´éšè¾“å…¥è§„æ¨¡å¢é•¿çš„å˜åŒ–
- ç©ºé—´å¤æ‚åº¦â€‹â€‹ï¼šç®—æ³•è¿è¡Œæ‰€éœ€å†…å­˜ç©ºé—´çš„å˜åŒ–

å¸¸è§æ—¶é—´å¤æ‚åº¦ï¼š
- O(1) - å›ºå®šæ—¶é—´ï¼ˆæœ€å¥½ï¼‰
- O(log n) - å¯¹æ•°æ—¶é—´ï¼ˆå¾ˆå¥½ï¼‰
- O(n) - çº¿æ€§æ—¶é—´ï¼ˆå¥½ï¼‰
- O(nÂ²) - å¹³æ–¹æ—¶é—´ï¼ˆè¾ƒå·®ï¼‰

ç¤ºä¾‹ï¼šæŸ¥æ‰¾åˆ—è¡¨ä¸­æ˜¯å¦å­˜åœ¨æŸå…ƒç´ 
```python
# ç®€å•æŸ¥æ‰¾ - O(n)
def simple_search(items, target):
    for item in items:
        if item == target:
            return True
    return False

# äºŒåˆ†æŸ¥æ‰¾ï¼ˆæœ‰åºåˆ—è¡¨ï¼‰- O(log n)
def binary_search(items, target):
    low, high = 0, len(items)-1
    while low <= high:
        mid = (low + high) // 2
        if items[mid] == target:
            return True
        elif items[mid] < target:
            low = mid + 1
        else:
            high = mid - 1
    return False
```

## ç®—æ³•åŸºç¡€
### 1. æœç´¢ç®—æ³•
åœ¨æ•°æ®é›†ä¸­æŸ¥æ‰¾ç‰¹å®šå…ƒç´ ï¼š
| æ–¹æ³•       | åœºæ™¯         | ä¼˜ç‚¹         | ç¼ºç‚¹               |
|------------|--------------|--------------|--------------------|
| çº¿æ€§æœç´¢   | æ— åºåˆ—è¡¨     | ç®€å•ç›´æ¥     | æ•ˆç‡ä½(O(n))      |
| äºŒåˆ†æœç´¢   | æœ‰åºåˆ—è¡¨     | é«˜æ•ˆ(O(log n)) | è¦æ±‚åˆ—è¡¨æœ‰åº       |

ç¤ºä¾‹ï¼šäºŒåˆ†æŸ¥æ‰¾å®ç°
```python
def binary_search(items, target):
    # èµ·ç‚¹å’Œç»ˆç‚¹ç´¢å¼•
    low, high = 0, len(items)-1
    
    while low <= high:
        # è®¡ç®—ä¸­é—´ä½ç½®
        mid = (low + high) // 2
        mid_value = items[mid]
        
        # æ‰¾åˆ°ç›®æ ‡
        if mid_value == target:
            return mid
        
        # ç›®æ ‡åœ¨å³ä¾§
        elif mid_value < target:
            low = mid + 1
        
        # ç›®æ ‡åœ¨å·¦ä¾§
        else:
            high = mid - 1
    
    # æœªæ‰¾åˆ°
    return -1
```
### 2. æ’åºç®—æ³•
é‡æ–°æ’åˆ—å…ƒç´ é¡ºåºï¼š
| æ–¹æ³•       | å¹³å‡å¤æ‚åº¦       | ç‰¹ç‚¹              |
|------------|------------------|-------------------|
| å†’æ³¡æ’åº   | \( O(n^2) \)     | ç®€å•ä½†æ…¢          |
| å¿«é€Ÿæ’åº   | \( O(n \log n) \) | é«˜æ•ˆï¼Œå¸¸ç”¨        |
| å½’å¹¶æ’åº   | \( O(n \log n) \) | ç¨³å®šï¼Œå¤§æ•°æ®å¤„ç†  |

å¿«é€Ÿæ’åºç¤ºä¾‹ï¼š
```python
def quicksort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]  # é€‰æ‹©ä¸­é—´å€¼ä½œä¸ºåŸºå‡†
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quicksort(left) + middle + quicksort(right)
```
### 3. åŠ¨æ€è§„åˆ’
æŠŠå¤§é—®é¢˜åˆ†è§£æˆå°é—®é¢˜ï¼Œå¹¶å­˜å‚¨å°é—®é¢˜ç»“æœï¼š
- é€‚åˆæ±‚è§£ï¼šæ–æ³¢é‚£å¥‘æ•°åˆ—ã€æœ€çŸ­è·¯å¾„ç­‰
- æ ¸å¿ƒæ€æƒ³ï¼šé¿å…é‡å¤è®¡ç®—ï¼Œä½¿ç”¨ç¼“å­˜
æ–æ³¢é‚£å¥‘æ•°åˆ—åŠ¨æ€è§„åˆ’å®ç°ï¼š
```python
def fib(n):
    # å­˜å‚¨è®¡ç®—ç»“æœ
    cache = [0, 1]  
    
    # ä»2å¼€å§‹è®¡ç®—å¹¶å­˜å‚¨ç»“æœ
    for i in range(2, n+1):
        cache.append(cache[i-1] + cache[i-2])
    
    return cache[n]

print(fib(10))  # è¾“å‡º: 55
```
### 4. è´ªå¿ƒç®—æ³•
æ¯ä¸€æ­¥éƒ½é€‰æ‹©å½“å‰æœ€ä¼˜è§£ï¼š
- ç‰¹ç‚¹ï¼šç®€å•é«˜æ•ˆï¼Œä½†ä¸ä¸€å®šèƒ½å¾—åˆ°å…¨å±€æœ€ä¼˜
- åº”ç”¨åœºæ™¯ï¼šé›¶é’±å…‘æ¢ã€å“ˆå¤«æ›¼ç¼–ç ç­‰
é›¶é’±å…‘æ¢ç¤ºä¾‹ï¼š
```python
def coin_change(coins, amount):
    # æ’åºç¡¬å¸ï¼ˆä»å¤§åˆ°å°ï¼‰
    coins.sort(reverse=True)
    result = []
    
    # å°è¯•ä½¿ç”¨æ¯ä¸ªç¡¬å¸
    for coin in coins:
        while amount >= coin:
            amount -= coin
            result.append(coin)
    
    return result

# ç”¨æœ€å°‘ç¡¬å¸ç»„æˆ86åˆ†
coins = [1, 5, 10, 25]
print(coin_change(coins, 86))  # [25, 25, 25, 10, 1]
```

## Git/GitHub ç‰ˆæœ¬æ§åˆ¶
### 1. ç‰ˆæœ¬æ§åˆ¶åŸºç¡€
ä»€ä¹ˆæ˜¯ç‰ˆæœ¬æ§åˆ¶ï¼Ÿè®°å½•æ–‡ä»¶å˜åŒ–çš„å†å²è®°å½•ç³»ç»Ÿ
æ ¸å¿ƒæ¦‚å¿µï¼š
- ä»“åº“ï¼ˆRepositoryï¼‰â€‹â€‹ï¼šé¡¹ç›®çš„æ–‡ä»¶å¤¹åŠå…¶å†å²è®°å½•
- æäº¤ï¼ˆCommitï¼‰â€‹â€‹ï¼šä¸€æ¬¡ç‰ˆæœ¬ä¿å­˜ï¼ˆå«æè¿°ä¿¡æ¯ï¼‰
- åˆ†æ”¯ï¼ˆBranchï¼‰â€‹â€‹ï¼šéš”ç¦»çš„å®éªŒç©ºé—´
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph LR
    A[å¼€å§‹] --> B[ä¿®æ”¹æ–‡ä»¶]
    B --> C[æ·»åŠ å˜æ›´åˆ°æš‚å­˜åŒº]
    C --> D[åˆ›å»ºæäº¤]
    D --> E[æ¨é€åˆ°è¿œç¨‹ä»“åº“]
```

### 2. åˆ†æ”¯ç®¡ç†
åœ¨ä¸åŒåˆ†æ”¯ä¸Šè¿›è¡Œå¼€å‘ï¼š
```bash
# 1. åˆ›å»ºæ–°åˆ†æ”¯
git branch new-feature

# 2. åˆ‡æ¢åˆ°è¯¥åˆ†æ”¯
git checkout new-feature

# 3. åœ¨æ–°åˆ†æ”¯ä¸Šè¿›è¡Œå¼€å‘ä¿®æ”¹...
git add .
git commit -m "æ·»åŠ æ–°åŠŸèƒ½"

# 4. å®Œæˆååˆå¹¶åˆ°ä¸»åˆ†æ”¯
git checkout main
git merge new-feature

# 5. æ¨é€åˆ°è¿œç¨‹ä»“åº“
git push origin main
```
### 3. åˆå¹¶è¯·æ±‚å·¥ä½œæµï¼ˆPull Requestï¼‰
å›¢é˜Ÿåä½œçš„æ ‡å‡†æµç¨‹ï¼š
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
sequenceDiagram
    participant A as å¼€å‘è€…
    participant B as GitHub
    participant C as å›¢é˜Ÿé¢†å¯¼
    
    A->>B: 1. æ¨é€ç‰¹æ€§åˆ†æ”¯
    A->>B: 2. åˆ›å»ºPull Request
    C->>B: 3. å®¡æŸ¥ä»£ç 
    C->>B: 4. æ‰¹å‡†è¯·æ±‚
    B->>B: 5. è‡ªåŠ¨åˆå¹¶ä»£ç 
```
### 4. ä»£ç åä½œæœ€ä½³å®è·µ
1.â€‹â€‹æ¯æ—¥æäº¤â€‹â€‹ï¼šå°æ­¥å‰è¿›ï¼Œå¤šæ¬¡æäº¤  
2.â€‹â€‹æ¸…æ™°çš„æäº¤ä¿¡æ¯â€‹â€‹ï¼š
```bash
# å·®çš„ä¿¡æ¯: "ä¿®å¤é—®é¢˜"
# å¥½çš„ä¿¡æ¯: "ä¿®å¤ç™»å½•é¡µé¢éªŒè¯ç ä¸æ˜¾ç¤ºçš„é—®é¢˜"
```
â€‹â€‹3.åˆ†æ”¯å‘½åè§„èŒƒâ€‹â€‹ï¼š
- feature/user-authenticationï¼ˆæ–°åŠŸèƒ½ï¼‰
- fix/button-alignmentï¼ˆä¿®å¤é—®é¢˜ï¼‰  

4.ä½¿ç”¨.gitignoreæ–‡ä»¶æ’é™¤ä¸éœ€è¦è·Ÿè¸ªçš„æ–‡ä»¶  

5.å®šæœŸgit pullæ‹‰å–ä»–äººæ›´æ”¹ï¼Œå‡å°‘å†²çª

## [æ•°å­¦åŸºç¡€å…¥é—¨ï¼šå°ç™½ä¹Ÿèƒ½æ‡‚çš„AIæ•°å­¦](Python-and-Math/math.md)

### çº¿æ€§ä»£æ•° - æ•°æ®çš„åŸºæœ¬éª¨æ¶
#### 1. çŸ©é˜µè¿ç®—ï¼šæ•°æ®çš„è¡¨æ ¼
çŸ©é˜µå°±åƒExcelè¡¨æ ¼ï¼Œç”¨æ¥ç»„ç»‡æ•°å­—ï¼š
```python
import numpy as np

# åˆ›å»º2x2çŸ©é˜µ
matrix = np.array([[1, 2], 
                   [3, 4]])
                   
# çŸ©é˜µåŠ æ³•
matrix + 2  # æ‰€æœ‰å…ƒç´ åŠ 2 â†’ [[3,4],[5,6]]

# çŸ©é˜µä¹˜æ³•
np.dot(matrix, matrix)  # çŸ©é˜µè‡ªä¹˜ â†’ [[7,10],[15,22]]
```
#### 2. å‘é‡ç©ºé—´ï¼šç®­å¤´æŒ‡å‘çš„æ–¹å‘
å‘é‡å°±åƒå¸¦æ–¹å‘çš„ç®­å¤´ï¼š
```python
# åœ¨ä¸‰ç»´ç©ºé—´ä¸­çš„ä¸¤ä¸ªå‘é‡
vector_a = np.array([1, 2, 3])
vector_b = np.array([4, 5, 6])

# å‘é‡çš„ç‚¹ç§¯ï¼ˆæŠ•å½±ï¼‰
dot_product = np.dot(vector_a, vector_b)  # 1Ã—4 + 2Ã—5 + 3Ã—6 = 32

# å‘é‡é•¿åº¦
length_a = np.linalg.norm(vector_a)  # âˆš(1Â²+2Â²+3Â²) â‰ˆ 3.74
```
#### 3. ç‰¹å¾å€¼/ç‰¹å¾å‘é‡ï¼šçŸ©é˜µçš„æœ¬è´¨
å½“çŸ©é˜µä½œç”¨åœ¨ç‰¹å®šå‘é‡ä¸Šæ—¶ä¸æ”¹å˜æ–¹å‘ï¼š
```python
# æ±‚çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
matrix = np.array([[2, 1],
                   [1, 2]])
                   
eigenvalues, eigenvectors = np.linalg.eig(matrix)

print("ç‰¹å¾å€¼:", eigenvalues)    # [3., 1.]
print("ç‰¹å¾å‘é‡:\n", eigenvectors)  # [[ 0.707, -0.707], [0.707, 0.707]]
```
#### 4. å¥‡å¼‚å€¼åˆ†è§£(SVD)ï¼šæ•°æ®çš„æœ¬è´¨æ‹†åˆ†
å°†ä»»æ„çŸ©é˜µåˆ†è§£ä¸ºä¸‰ä¸ªç‰¹æ®ŠçŸ©é˜µç›¸ä¹˜ï¼š
```python
# å›¾åƒå‹ç¼©ç¤ºä¾‹ï¼ˆå®é™…åº”ç”¨ä¸­ï¼‰
from skimage import data
from skimage.transform import resize
import matplotlib.pyplot as plt

# åŠ è½½å°å›¾åƒ
image = resize(data.astronaut(), (100, 100))
gray_image = np.mean(image, axis=2)

# è¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£
U, s, VT = np.linalg.svd(gray_image, full_matrices=False)

# ä»…ä¿ç•™å‰20ä¸ªç‰¹å¾é‡å»ºå›¾åƒ
k = 20
reconstructed = U[:, :k] @ np.diag(s[:k]) @ VT[:k, :]

# æ˜¾ç¤ºå‹ç¼©å‰åå¯¹æ¯”
fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(gray_image, cmap='gray')
ax1.set_title('åŸå§‹å›¾åƒ')
ax2.imshow(reconstructed, cmap='gray')
ax2.set_title('å‹ç¼©åå›¾åƒ (SVD)')
plt.show()
```
### æ¦‚ç‡ç»Ÿè®¡ - é¢„æµ‹ä¸ä¸ç¡®å®šæ€§çš„è‰ºæœ¯
#### 1. æ¦‚ç‡åˆ†å¸ƒï¼šäº‹ä»¶å‘ç”Ÿçš„å¯èƒ½æ€§
```python
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import norm, binom, poisson

# æ­£æ€åˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰
x = np.linspace(-5, 5, 100)
plt.plot(x, norm.pdf(x, 0, 1), label='æ­£æ€åˆ†å¸ƒ')

# äºŒé¡¹åˆ†å¸ƒï¼ˆæŠ›ç¡¬å¸ï¼‰
n, p = 10, 0.5
x_binom = np.arange(0, 11)
plt.stem(x_binom, binom.pmf(x_binom, n, p), 'bo', label='äºŒé¡¹åˆ†å¸ƒ')

# æ³Šæ¾åˆ†å¸ƒï¼ˆç½•è§äº‹ä»¶ï¼‰
lambda_ = 3
x_poisson = np.arange(0, 10)
plt.stem(x_poisson, poisson.pmf(x_poisson, lambda_), 'g^', label='æ³Šæ¾åˆ†å¸ƒ')

plt.legend()
plt.title('å¸¸è§æ¦‚ç‡åˆ†å¸ƒ')
plt.xlabel('æ•°å€¼')
plt.ylabel('æ¦‚ç‡å¯†åº¦')
plt.show()
```
#### 2. è´å¶æ–¯å®šç†ï¼šæ–°è¯æ®æ›´æ–°ä¿¡å¿µ
**åŒ»ç”Ÿè¯Šæ–­ç–¾ç—…çš„æƒ…æ™¯ï¼šâ€‹**
- å‡è®¾ï¼š
+ ç–¾ç—…Dæ‚£ç—…ç‡: 1% â†’ P(D) = 0.01
+ æ£€æµ‹çµæ•åº¦: 99% â†’ P(é˜³æ€§|D) = 0.99
+ æ£€æµ‹ç‰¹å¼‚åº¦: 95% â†’ P(é˜´æ€§|å¥åº·) = 0.95
æ±‚P(ç¡®å®æœ‰ç—…|æ£€æµ‹é˜³æ€§)?
```python
# è®¡ç®—è´å¶æ–¯æ¦‚ç‡
p_disease = 0.01      # P(D)
p_positive_given_disease = 0.99  # P(é˜³æ€§|D)
p_negative_given_healthy = 0.95  # P(é˜´æ€§|å¥åº·)

# P(é˜³æ€§|å¥åº·) = 1 - P(é˜´æ€§|å¥åº·)
p_positive_given_healthy = 1 - p_negative_given_healthy

# P(é˜³æ€§) = P(é˜³æ€§|D) * P(D) + P(é˜³æ€§|å¥åº·) * P(å¥åº·)
p_positive = (p_positive_given_disease * p_disease) + (p_positive_given_healthy * (1-p_disease))

# P(D|é˜³æ€§) = [P(é˜³æ€§|D) * P(D)] / P(é˜³æ€§)
p_disease_given_positive = (p_positive_given_disease * p_disease) / p_positive

print(f"æ£€æµ‹é˜³æ€§åçœŸæ­£æ‚£ç—…çš„æ¦‚ç‡: {p_disease_given_positive*100:.2f}%")  # â‰ˆ16.2%
```
#### 3. å‡è®¾æ£€éªŒï¼šåˆ¤æ–­å·®å¼‚æ˜¯å¦çœŸå®
**â€‹â€‹å­¦ç”ŸAå’ŒBè°æˆç»©æ›´å¥½**â€‹â€‹
+ Aç­å¹³å‡åˆ†ï¼š78åˆ†ï¼ˆ30äººï¼‰
+ Bç­å¹³å‡åˆ†ï¼š82åˆ†ï¼ˆ30äººï¼‰
+ å·®å¼‚æ˜¾è‘—å—ï¼Ÿ
```python
from scipy import stats

# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆæ–¹å·®ä¸º10ï¼‰
np.random.seed(42)
class_a = np.random.normal(78, 10, 30)
class_b = np.random.normal(82, 10, 30)

# è¿›è¡Œtæ£€éªŒ
t_stat, p_value = stats.ttest_ind(class_a, class_b)

alpha = 0.05  # æ˜¾è‘—æ€§æ°´å¹³
if p_value < alpha:
    print(f"på€¼ = {p_value:.4f} < 0.05ï¼Œä¸¤ç»„æœ‰æ˜¾è‘—å·®å¼‚")
else:
    print(f"på€¼ = {p_value:.4f} >= 0.05ï¼Œä¸¤ç»„æ— æ˜¾è‘—å·®å¼‚")
```
#### 4. å›å½’åˆ†æï¼šé¢„æµ‹è¶‹åŠ¿
æ ¹æ®æˆ¿å±‹é¢ç§¯é¢„æµ‹ä»·æ ¼ï¼š
```python
from sklearn.linear_model import LinearRegression

# æ ·æœ¬æ•°æ®ï¼ˆé¢ç§¯ vs ä»·æ ¼ï¼‰
areas = np.array([50, 70, 90, 110, 130]).reshape(-1, 1)  # mÂ²
prices = np.array([200, 240, 290, 340, 380])  # ä¸‡å…ƒ

# åˆ›å»ºæ¨¡å‹å¹¶æ‹Ÿåˆ
model = LinearRegression()
model.fit(areas, prices)

# é¢„æµ‹80å¹³ç±³æˆ¿å­çš„ä»·æ ¼
prediction = model.predict([[80]])
print(f"é¢„æµ‹80å¹³ç±³æˆ¿å±‹ä»·æ ¼ï¼š{prediction[0]:.1f}ä¸‡å…ƒ")

# ç»˜åˆ¶æ•°æ®ç‚¹åŠæ‹Ÿåˆçº¿
plt.scatter(areas, prices, label='å®é™…ä»·æ ¼')
plt.plot(areas, model.predict(areas), 'r-', label='é¢„æµ‹è¶‹åŠ¿')
plt.scatter([80], prediction, c='g', marker='*', s=200, label='é¢„æµ‹ç‚¹')
plt.xlabel('é¢ç§¯(mÂ²)')
plt.ylabel('ä»·æ ¼(ä¸‡å…ƒ)')
plt.legend()
plt.show()
```
### å¾®ç§¯åˆ† - å˜åŒ–çš„æ•°å­¦è¯­è¨€
#### 1. å¯¼æ•°ä¸ç§¯åˆ†ï¼šå˜åŒ–ä¸ç´¯ç§¯  
> **â€‹â€‹å¯¼æ•° â‰ˆ ç¬æ—¶é€Ÿåº¦ï¼Œç§¯åˆ† â‰ˆ æ€»è·ç¦»â€‹**
```python
# æŸè½¦è¾†çš„è¿åŠ¨å‡½æ•°ï¼šä½ç½® = æ—¶é—´Â²
t = np.linspace(0, 5, 100)  # 0åˆ°5ç§’
position = t**2              # ä½ç½®å‡½æ•°

# è®¡ç®—å¯¼æ•°ï¼ˆé€Ÿåº¦ï¼‰
# å¯¼æ•°çš„æ•°å€¼è®¡ç®—ï¼šdy/dx â‰ˆ Î”y/Î”x
velocity = np.gradient(position, t)  # 2t

# è®¡ç®—ç§¯åˆ†ï¼ˆæ€»è·¯ç¨‹ï¼‰
# ç§¯åˆ†çš„æ•°å€¼è®¡ç®—ï¼ˆç´¯åŠ ï¼‰
distance = np.cumsum(velocity * np.diff(t, prepend=0))

# ç»˜åˆ¶ç»“æœ
plt.figure(figsize=(10, 6))
plt.subplot(211)
plt.plot(t, position, 'b-', label='ä½ç½®')
plt.plot(t, velocity, 'g--', label='é€Ÿåº¦(å¯¼æ•°)')
plt.legend()
plt.title('ä½ç½®ä¸é€Ÿåº¦å…³ç³»')

plt.subplot(212)
plt.plot(t, distance, 'r-', label='è·¯ç¨‹(ç§¯åˆ†)')
plt.legend()
plt.xlabel('æ—¶é—´(ç§’)')
plt.show()
```
#### 2. åå¯¼æ•°ï¼šå¤šç»´ç©ºé—´çš„å˜åŒ–ç‡
æ¸©åº¦åœºçš„å˜åŒ–ï¼ˆéšæ—¶é—´+ä½ç½®ï¼‰ï¼š
```python
from mpl_toolkits.mplot3d import Axes3D

# åˆ›å»ºæ—¶é—´å’Œç©ºé—´çš„ç½‘æ ¼
x = np.linspace(0, 10, 100)  # ç©ºé—´åæ ‡
t = np.linspace(0, 5, 100)    # æ—¶é—´åæ ‡
X, T = np.meshgrid(x, t)

# æ¸©åº¦å‡½æ•°ï¼šæ¸©åº¦ = e^{-0.1t} * sin(x)
Z = np.exp(-0.1*T) * np.sin(X)

# ç»˜åˆ¶3Dæ¸©åº¦åœº
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(X, T, Z, cmap='viridis')
ax.set_xlabel('ä½ç½®(x)')
ax.set_ylabel('æ—¶é—´(t)')
ax.set_zlabel('æ¸©åº¦(â„ƒ)')
ax.set_title('ç©ºé—´æ¸©åº¦åˆ†å¸ƒéšæ—¶é—´å˜åŒ–')
plt.show()
```
#### 3. æ¢¯åº¦ï¼šæœ€é™¡çš„ä¸Šå±±æ–¹å‘
```python
# å®šä¹‰ä¸€ä¸ªå±±å³°å½¢çŠ¶çš„å‡½æ•°
def mountain(x, y):
    return np.exp(-0.1*(x**2 + y**2)) * np.cos(0.5*x)

# åˆ›å»ºç½‘æ ¼
x = np.linspace(-3, 3, 100)
y = np.linspace(-3, 3, 100)
X, Y = np.meshgrid(x, y)
Z = mountain(X, Y)

# è®¡ç®—æ¢¯åº¦ï¼ˆä¸‹å±±æ–¹å‘ï¼‰
gy, gx = np.gradient(Z)
skip = 5  # æ˜¾ç¤ºéƒ¨åˆ†ç®­å¤´

# ç»˜åˆ¶ç­‰é«˜çº¿å›¾
plt.figure(figsize=(10, 8))
plt.contourf(X, Y, Z, 20, cmap='viridis')
plt.colorbar()
plt.quiver(X[::skip, ::skip], Y[::skip, ::skip], 
           -gx[::skip, ::skip], -gy[::skip, ::skip], 
           scale=50, color='white')  # è´Ÿæ¢¯åº¦è¡¨ç¤ºæœ€é™¡ä¸‹é™æ–¹å‘
plt.title('åœ°å½¢æ¢¯åº¦å›¾ - ç™½è‰²ç®­å¤´æŒ‡å‘æœ€é™¡ä¸‹é™æ–¹å‘')
plt.xlabel('X')
plt.ylabel('Y')
plt.show()
```
#### 4. æ³°å‹’çº§æ•°ï¼šç”¨å¤šé¡¹å¼é€¼è¿‘å¤æ‚å‡½æ•°
ç”¨å¤šé¡¹å¼é€¼è¿‘æ­£å¼¦å‡½æ•°ï¼š
```python
# æ­£å¼¦å‡½æ•°åŠå…¶æ³°å‹’å±•å¼€
x = np.linspace(-10, 10, 500)
sin_x = np.sin(x)

# ä¸åŒé˜¶æ•°çš„æ³°å‹’å±•å¼€
taylor1 = x  # 1é˜¶
taylor3 = x - x**3/6  # 3é˜¶
taylor5 = taylor3 + x**5/120  # 5é˜¶

# ç»˜åˆ¶æ¯”è¾ƒå›¾
plt.figure(figsize=(10, 6))
plt.plot(x, sin_x, 'b-', lw=3, label='çœŸå® sin(x)')
plt.plot(x, taylor1, 'g--', label='1é˜¶å±•å¼€')
plt.plot(x, taylor3, 'r-.', label='3é˜¶å±•å¼€')
plt.plot(x, taylor5, 'm:', lw=2, label='5é˜¶å±•å¼€')
plt.ylim(-3, 3)
plt.legend()
plt.title('æ³°å‹’çº§æ•°é€¼è¿‘æ­£å¼¦å‡½æ•°')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.show()
```
### ä¼˜åŒ–ç†è®º - å¯»æ‰¾æœ€ä½³è§£å†³æ–¹æ¡ˆ
#### 1. æ¢¯åº¦ä¸‹é™ï¼šä¸€æ­¥ä¸€æ­¥æ‰¾åˆ°æœ€ä½ç‚¹
**å¯»æ‰¾å‡½æ•°æœ€ä½ç‚¹ï¼š**
```python
# å®šä¹‰å‡½æ•°ï¼šf(x) = x^4 - 3x^3 + 2
def f(x):
    return x**4 - 3*x**3 + 2

# å¯¼æ•°ï¼šf'(x) = 4x^3 - 9x^2
def df(x):
    return 4*x**3 - 9*x**2

# æ¢¯åº¦ä¸‹é™
x = 2.0     # åˆå§‹ç‚¹
lr = 0.01   # å­¦ä¹ ç‡
steps = 50  # è¿­ä»£æ¬¡æ•°

# è®°å½•è·¯å¾„
path = [x]

for i in range(steps):
    grad = df(x)
    x = x - lr * grad  # å‘ä¸‹èµ°ä¸€æ­¥
    path.append(x)
    
# ç»˜åˆ¶å‡½æ•°åŠä¸‹é™è·¯å¾„
x_vals = np.linspace(-1, 3, 200)
plt.plot(x_vals, f(x_vals), 'b-', lw=2, label='f(x)')
plt.scatter(path, f(np.array(path)), c='r', marker='o')
for i in range(1, len(path)):
    plt.annotate('', xy=(path[i], f(path[i])), 
                xytext=(path[i-1], f(path[i-1])),
                arrowprops=dict(arrowstyle='->', color='r'))
plt.xlabel('x')
plt.ylabel('f(x)')
plt.title('æ¢¯åº¦ä¸‹é™è¿‡ç¨‹')
plt.grid(True)
plt.show()
```
#### 2. çº¦æŸä¼˜åŒ–ï¼šå¸¦é™åˆ¶çš„æœ€ä¼˜åŒ–é—®é¢˜
```python
from scipy.optimize import minimize

# ç›®æ ‡å‡½æ•°ï¼šf(x,y) = (x-1)Â² + (y-2.5)Â²
objective = lambda x: (x[0]-1)**2 + (x[1]-2.5)**2

# çº¦æŸæ¡ä»¶ï¼š
# x - 2y >= -1    â†’ çº¦æŸ1
# -x - 2y >= -6   â†’ çº¦æŸ2
# -x + 2y >= -2   â†’ çº¦æŸ3
constraints = [
    {'type': 'ineq', 'fun': lambda x: x[0] - 2*x[1] + 1},  # â‰¥0
    {'type': 'ineq', 'fun': lambda x: -x[0] - 2*x[1] + 6},
    {'type': 'ineq', 'fun': lambda x: -x[0] + 2*x[1] + 2}
]

# åˆå§‹çŒœæµ‹
x0 = [0, 0]

# æ±‚è§£
solution = minimize(objective, x0, constraints=constraints)
print(f"æœ€å°å€¼ç‚¹: ({solution.x[0]:.2f}, {solution.x[1]:.2f})")
print(f"æœ€å°å€¼: {solution.fun:.4f}")
```
#### 3. å‡¸ä¼˜åŒ–åŸºç¡€ï¼šä¸ä¼šé™·å…¥å±€éƒ¨æœ€ä¼˜çš„ç‰¹ä¾‹
```
graph LR
    A[ä¼˜åŒ–é—®é¢˜] --> B{æ˜¯å¦ä¸ºå‡¸ï¼Ÿ}
    B -- æ˜¯ --> C[åªæœ‰ä¸€ä¸ªå…¨å±€æœ€ä¼˜è§£]
    B -- å¦ --> D[å¯èƒ½æœ‰å¤šä¸ªå±€éƒ¨æœ€ä¼˜è§£]
    
    subgraph å‡¸å‡½æ•°ç‰¹æ€§
    C --> E[äºŒé˜¶å¯¼æ•°>=0]
    C --> F[ä»»æ„è¿çº¿ä½äºå‡½æ•°ä¸Šæ–¹]
    C --> G[å±€éƒ¨æœ€ä¼˜å³å…¨å±€æœ€ä¼˜]
    end
```
å‡¸ä¼˜åŒ–çš„é»„é‡‘å®šå¾‹ï¼š
1. å‡¸é—®é¢˜æ€»èƒ½æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£  
2. æœºå™¨å­¦ä¹ ä¸­å¸¸å°†éå‡¸é—®é¢˜è½¬åŒ–ä¸ºå‡¸é—®é¢˜æ±‚è§£

#### 4. å­¦ä¹ ç‡ç­–ç•¥ï¼šæ™ºèƒ½è°ƒæ•´å­¦ä¹ æ­¥ä¼
ä¸åŒå­¦ä¹ ç‡ç­–ç•¥å¯¹æ¯”ï¼š
```python
# ä¸‰ç§å­¦ä¹ ç‡ç­–ç•¥
def constant_lr(epoch):  # å›ºå®šå­¦ä¹ ç‡
    return 0.1

def step_lr(epoch):     # é˜¶æ¢¯ä¸‹é™
    if epoch < 10:
        return 0.1
    elif epoch < 20:
        return 0.01
    else:
        return 0.001

def exp_lr(epoch):      # æŒ‡æ•°è¡°å‡
    return 0.1 * (0.9 ** epoch)

# ç»˜åˆ¶å­¦ä¹ ç‡å˜åŒ–æ›²çº¿
epochs = range(1, 31)

plt.plot(epochs, [constant_lr(e) for e in epochs], 'b-o', label='å›ºå®šå­¦ä¹ ç‡')
plt.plot(epochs, [step_lr(e) for e in epochs], 'r-s', label='é˜¶æ¢¯è¡°å‡')
plt.plot(epochs, [exp_lr(e) for e in epochs], 'g-^', label='æŒ‡æ•°è¡°å‡')
plt.xlabel('è®­ç»ƒè½®æ¬¡(epoch)')
plt.ylabel('å­¦ä¹ ç‡')
plt.title('ä¸åŒå­¦ä¹ ç‡ç­–ç•¥æ¯”è¾ƒ')
plt.legend()
plt.grid(True)
plt.show()
```
### æ•°å­¦åœ¨AIä¸­çš„å®é™…åº”ç”¨
**å…¸å‹AIä»»åŠ¡ä¸­æ¶‰åŠçš„æ•°å­¦ï¼š**
| AIæ¨¡å‹       | çº¿æ€§ä»£æ•° | æ¦‚ç‡ç»Ÿè®¡ | å¾®ç§¯åˆ† | ä¼˜åŒ–æ–¹æ³• |
|--------------|----------|----------|--------|----------|
| çº¿æ€§å›å½’     | â˜…â˜…       | â˜…â˜…       | â˜…      | â˜…â˜…       |
| ç¥ç»ç½‘ç»œ     | â˜…â˜…â˜…      | â˜…        | â˜…â˜…â˜…    | â˜…â˜…â˜…      |
| æ¨èç³»ç»Ÿ     | â˜…â˜…       | â˜…â˜…â˜…      | â˜…      | â˜…â˜…       |
| å›¾åƒå¤„ç†     | â˜…â˜…â˜…      | â˜…        | â˜…      | â˜…â˜…       |
| å¼ºåŒ–å­¦ä¹      | â˜…        | â˜…â˜…â˜…      | â˜…â˜…     | â˜…â˜…â˜…      |
**å­¦ä¹ å»ºè®®ï¼š**
â€‹â€‹1. ç†è§£ > è®°å¿†â€‹â€‹ï¼šå…ˆææ‡‚æ¦‚å¿µï¼Œå…¬å¼è‡ªç„¶è®°ä½  
â€‹â€‹2. å¯è§†åŒ–æ˜¯åˆ©å™¨â€‹â€‹ï¼šå¤šç”»å›¾å¸®åŠ©ç†è§£æŠ½è±¡æ¦‚å¿µ  
3. â€‹â€‹åŠ¨æ‰‹è®¡ç®—â€‹â€‹ï¼šPythonå·¥å…·åŒ…æ˜¯æ•°å­¦å­¦ä¹ å¥½å¸®æ‰‹  
4. â€‹â€‹å®é™…åº”ç”¨é©±åŠ¨â€‹â€‹ï¼šå…³æ³¨çŸ¥è¯†åœ¨AIä¸­çš„å…·ä½“ç”¨é€”  

> é€šè¿‡è¿™ä»½æ•™ç¨‹ï¼Œæ‚¨å·²ç»åˆæ­¥æŒæ¡äº†AIæ‰€éœ€çš„æ•°å­¦åŸºç¡€ã€‚
>> æ•°å­¦å°±åƒç¼–ç¨‹çš„"å†…åŠŸ"ï¼Œéœ€è¦**æŒç»­ç»ƒä¹ **æ‰èƒ½çœŸæ­£ç†è§£å…¶ç²¾é«“ï¼

---

# **<h3 id="2">[ğŸ¯ é˜¶æ®µ 1ï¼šæœºå™¨å­¦ä¹ ï¼šé›¶åŸºç¡€å…¥é—¨æŒ‡å—](https://github.com/0voice/learning-Journey-AI/tree/main/Machine%20Learning)</h3>**


> ***ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ*** æƒ³è±¡ä¸€ä¸‹ï¼Œä½ åœ¨æ•™å­©å­åŒºåˆ†çŒ«å’Œç‹—ï¼šä¸æ˜¯ç›´æ¥å‘Šè¯‰ä»–è§„åˆ™ï¼Œè€Œæ˜¯ç»™ä»–çœ‹å„ç§çŒ«ç‹—å›¾ç‰‡ï¼Œè®©ä»–è‡ªå·±æ€»ç»“ç‰¹å¾ã€‚
>> **è¿™å°±æ˜¯æœºå™¨å­¦ä¹ ï¼è®©è®¡ç®—æœºé€šè¿‡å¤§é‡æ•°æ®è‡ªå·±å‘ç°è§„å¾‹ã€‚**
  
**æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹æ€»ç»“**
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph TD
    A[ç†è§£é—®é¢˜] --> B[æ•°æ®æ”¶é›†]
    B --> C[æ•°æ®é¢„å¤„ç†]
    C --> D[æ¨¡å‹é€‰æ‹©]
    D --> E[æ¨¡å‹è®­ç»ƒ]
    E --> F[æ¨¡å‹è¯„ä¼°]
    F --> G{æ•ˆæœæ»¡æ„?}
    G -->|å¦| D
    G -->|æ˜¯| H[è¶…å‚æ•°è°ƒä¼˜]
    H --> I[æœ€ç»ˆæ¨¡å‹è¯„ä¼°]
    I --> J[æ¨¡å‹éƒ¨ç½²]
```

**æ¥ä¸‹æ¥æˆ‘ä»¬ä»ä»¥ä¸‹å‡ ä¸ªç‚¹å¼€å§‹è®²è§£**  

- **ç›‘ç£å­¦ä¹ **  
  çº¿æ€§/é€»è¾‘å›å½’ Â· SVM Â· å†³ç­–æ ‘ Â· é›†æˆæ–¹æ³•
- **æ— ç›‘ç£å­¦ä¹ **  
  èšç±»(K-means, DBSCAN) Â· é™ç»´(PCA, t-SNE)
- **æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–**  
  äº¤å‰éªŒè¯ Â· è¶…å‚æ•°è°ƒä¼˜ Â· è¯„ä¼°æŒ‡æ ‡

  
## ç›‘ç£å­¦ä¹ ï¼šæœ‰è€å¸ˆçš„æŒ‡å¯¼å­¦ä¹ 
### 1. çº¿æ€§å›å½’ï¼šé¢„æµ‹è¿ç»­å€¼
- â€‹â€‹æ ¸å¿ƒæ€æƒ³â€‹â€‹ï¼šæ‰¾åˆ°ä¸€æ¡æœ€ä½³æ‹Ÿåˆçº¿ï¼Œé¢„æµ‹è¿ç»­å€¼ç»“æœ
- å®ä¾‹åº”ç”¨â€‹â€‹ï¼šæ ¹æ®æˆ¿å­é¢ç§¯é¢„æµ‹æˆ¿ä»·
```python
# ç®€å•çº¿æ€§å›å½’ç¤ºä¾‹
import numpy as np
from sklearn.linear_model import LinearRegression

# æˆ¿å­é¢ç§¯æ•°æ®ï¼ˆå¹³æ–¹ç±³ï¼‰
house_sizes = np.array([50, 70, 90, 110]).reshape(-1, 1)
# å¯¹åº”æˆ¿ä»·ï¼ˆä¸‡å…ƒï¼‰
prices = np.array([300, 400, 500, 600])

# åˆ›å»ºæ¨¡å‹å¹¶è®­ç»ƒ
model = LinearRegression()
model.fit(house_sizes, prices)

# é¢„æµ‹120å¹³æˆ¿å­çš„ä»·æ ¼
prediction = model.predict([[120]])
print(f"é¢„æµ‹æˆ¿ä»·: {prediction[0]:.1f}ä¸‡å…ƒ")  # è¾“å‡º: é¢„æµ‹æˆ¿ä»·: 700.0ä¸‡å…ƒ
```

### 2. é€»è¾‘å›å½’ï¼šè§£å†³äºŒåˆ†ç±»é—®é¢˜  

- â€‹â€‹æ ¸å¿ƒæ€æƒ³â€‹â€‹ï¼šè®¡ç®—æŸä»¶äº‹å‘ç”Ÿçš„æ¦‚ç‡ï¼ˆ0-1ä¹‹é—´ï¼‰  
- â€‹â€‹å®ä¾‹åº”ç”¨â€‹â€‹ï¼šåˆ¤æ–­é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶
```python
# åƒåœ¾é‚®ä»¶è¯†åˆ«ç¤ºä¾‹
from sklearn.linear_model import LogisticRegression

# å‡è®¾æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
# feature1: é‚®ä»¶åŒ…å«"å…è´¹"æ¬¡æ•°
# feature2: é‚®ä»¶åŒ…å«"è·å¥–"æ¬¡æ•°
X_train = [[3, 1], [5, 2], [1, 0], [0, 1]]  # è®­ç»ƒæ•°æ®
y_train = [1, 1, 0, 0]  # 1=åƒåœ¾é‚®ä»¶ï¼Œ0=æ­£å¸¸é‚®ä»¶

# åˆ›å»ºæ¨¡å‹å¹¶è®­ç»ƒ
spam_detector = LogisticRegression()
spam_detector.fit(X_train, y_train)

# é¢„æµ‹æ–°é‚®ä»¶
new_email = [[4, 3]]  # åŒ…å«4æ¬¡"å…è´¹"ï¼Œ3æ¬¡"è·å¥–"
prediction = spam_detector.predict(new_email)
print("åƒåœ¾é‚®ä»¶" if prediction[0] == 1 else "æ­£å¸¸é‚®ä»¶")  # è¾“å‡º: åƒåœ¾é‚®ä»¶
```

### 3. æ”¯æŒå‘é‡æœº(SVM)ï¼šæ‰¾æœ€ä½³å†³ç­–è¾¹ç•Œ  
- æ ¸å¿ƒæ€æƒ³â€‹â€‹ï¼šåœ¨æ•°æ®ç‚¹ä¹‹é—´æ‰¾åˆ°æœ€å®½çš„"éš”ç¦»å¸¦"â€‹â€‹
- å®ä¾‹åº”ç”¨â€‹â€‹ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«  
 åŸºç¡€æ¦‚å¿µå›¾ç¤ºï¼š
```mermaid
graph TD
    A[æ”¯æŒå‘é‡æœºæ ¸å¿ƒæ€æƒ³] --> B[å¯»æ‰¾æœ€ä½³è¶…å¹³é¢]
    A --> C[æœ€å¤§åŒ–åˆ†ç±»é—´éš”]
    A --> D[å¤„ç†éçº¿æ€§æ•°æ®]
    style A fill:#f9f,stroke:#333
```

### 4. å†³ç­–æ ‘ï¼šæ ‘çŠ¶å†³ç­–æ¨¡å‹
- â€‹â€‹å·¥ä½œåŸç†â€‹â€‹ï¼šåƒ"20ä¸ªé—®é¢˜"æ¸¸æˆï¼Œé€šè¿‡ä¸€ç³»åˆ—é—®é¢˜å¾—å‡ºç»“è®º
â€‹â€‹- å®ä¾‹åº”ç”¨â€‹â€‹ï¼šè´·æ¬¾å®¡æ‰¹å†³ç­–
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph TD
    A[æ”¶å…¥>2ä¸‡ï¼Ÿ] -->|æ˜¯| B[ä¿¡ç”¨è¯„åˆ†>700ï¼Ÿ]
    A -->|å¦| C[æ‹’ç»è´·æ¬¾]
    B -->|æ˜¯| D[æ‰¹å‡†è´·æ¬¾]
    B -->|å¦| E[æä¾›æŠµæŠ¼ï¼Ÿ]
    E -->|æ˜¯| D
    E -->|å¦| C
```

### 5. é›†æˆæ–¹æ³•ï¼šå›¢ç»“åŠ›é‡å¤§
ä¸‰ç§å¸¸ç”¨æ–¹æ³•ï¼š
| æ–¹æ³•         | å·¥ä½œåŸç†                     | ä¼˜ç‚¹                  |
|--------------|----------------------------|-----------------------|
| éšæœºæ£®æ—     | å¤šæ£µæ ‘å…±åŒæŠ•ç¥¨               | æŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›å¼º        |
| æ¢¯åº¦æå‡æ ‘   | åä¸€æ£µæ ‘ä¿®æ­£å‰ä¸€æ£µæ ‘çš„é”™è¯¯    | é¢„æµ‹ç²¾åº¦é«˜            |
| AdaBoost     | é‡ç‚¹è®­ç»ƒéš¾åˆ†ç±»æ ·æœ¬           | å¤„ç†ä¸å¹³è¡¡æ•°æ®        |

## æ— ç›‘ç£å­¦ä¹ ï¼šæ— äººæŒ‡å¯¼çš„è‡ªæˆ‘å‘ç°
### 1. èšç±»åˆ†æï¼šç‰©ä»¥ç±»èš
**K-meansèšç±»**  
- â€‹â€‹å·¥ä½œåŸç†â€‹â€‹ï¼šè‡ªåŠ¨å°†æ•°æ®åˆ†æˆKä¸ªç°‡
- â€‹â€‹å®ä¾‹åº”ç”¨â€‹â€‹ï¼šå¸‚åœºç»†åˆ†åˆ†æ
```python
# å®¢æˆ·åˆ†ç¾¤ç¤ºä¾‹
from sklearn.cluster import KMeans
import numpy as np

# å‡è®¾æœ‰ä¸¤ç§å®¢æˆ·ç‰¹å¾ï¼šè´­ä¹°é¢‘ç‡å’Œå¹³å‡å®¢å•ä»·
customer_data = np.array([
    [1, 100],   # å®¢æˆ·1
    [5, 500],   # å®¢æˆ·2
    [1, 150],   # å®¢æˆ·3
    [6, 550]    # å®¢æˆ·4
])

# åˆ›å»ºK=2çš„èšç±»æ¨¡å‹
kmeans = KMeans(n_clusters=2)
kmeans.fit(customer_data)

# æŸ¥çœ‹åˆ†ç¾¤ç»“æœ
print("å®¢æˆ·åˆ†ç¾¤ç»“æœ:", kmeans.labels_)
# å¯èƒ½è¾“å‡º: [0, 1, 0, 1] è¡¨ç¤ºåˆ†æˆä¸¤ç»„
```
**K-meanså¯è§†åŒ–è¿‡ç¨‹ï¼š**
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph LR
    A[éšæœºé€‰æ‹©ä¸­å¿ƒç‚¹] --> B[å°†ç‚¹åˆ†é…åˆ°æœ€è¿‘ä¸­å¿ƒ]
    B --> C[é‡æ–°è®¡ç®—ä¸­å¿ƒç‚¹ä½ç½®]
    C --> D{ä¸­å¿ƒç‚¹å˜åŒ–?}
    D -->|æ˜¯| B
    D -->|å¦| E[è¾“å‡ºèšç±»ç»“æœ]
```
**DBSCANèšç±»**
- â€‹â€‹ç‰¹ç‚¹â€‹â€‹ï¼šè‡ªåŠ¨å‘ç°ä»»æ„å½¢çŠ¶çš„èšç±»ç°‡
â€‹â€‹- é€‚ç”¨åœºæ™¯â€‹â€‹ï¼šåœ°ç†æ•°æ®èšç±»

### 2. é™ç»´æŠ€æœ¯ï¼šåŒ–ç¹ä¸ºç®€
**ä¸»æˆåˆ†åˆ†æ(PCA)**  
- â€‹â€‹å·¥ä½œåŸç†â€‹â€‹ï¼šå°†é«˜ç»´æ•°æ®å‹ç¼©åˆ°å…³é”®ç»´åº¦
- â€‹â€‹å®ä¾‹åº”ç”¨â€‹â€‹ï¼šäººè„¸è¯†åˆ«ç‰¹å¾æå–
```python
# PCAé™ç»´ç¤ºä¾‹
from sklearn.decomposition import PCA
import numpy as np

# åˆ›å»ºä¸€äº›ä¸‰ç»´æ•°æ®
data = np.array([
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
])

# åˆ›å»ºPCAæ¨¡å‹ï¼Œé™åˆ°äºŒç»´
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(data)

print("é™ç»´åæ•°æ®:")
print(reduced_data)
```
**t-SNEæŠ€æœ¯**
-â€‹â€‹ ç‰¹ç‚¹â€‹â€‹ï¼šä¿æŒç›¸ä¼¼ç‚¹å½¼æ­¤æ¥è¿‘
â€‹â€‹- é€‚ç”¨åœºæ™¯â€‹â€‹ï¼šé«˜ç»´æ•°æ®å¯è§†åŒ–ï¼ˆå¦‚MNISTæ‰‹å†™æ•°å­—ï¼‰

## æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–
### 1. è¯„ä¼°æŒ‡æ ‡ï¼šè€ƒå·è¯„åˆ†
**å›å½’é—®é¢˜æŒ‡æ ‡:**
| æŒ‡æ ‡   | å…¬å¼                               | ç‰¹ç‚¹                     |
|--------|-----------------------------------|--------------------------|
| MAE    | \( \frac{1}{n}\sum_{i=1}^{n} \|y_i - \hat{y_i}\| \) | é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¹³å‡ç»å¯¹è¯¯å·® |
| MSE    | \( \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2 \) | å¯¹å¤§è¯¯å·®æƒ©ç½šæ›´å¤§           |
| RÂ²     | \( 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} \) | è¡¨ç¤ºæ¨¡å‹è§£é‡ŠåŠ›           |

**åˆ†ç±»é—®é¢˜æŒ‡æ ‡:**
| æŒ‡æ ‡     | è®¡ç®—å…¬å¼                                | é€‚ç”¨åœºæ™¯             |
|----------|----------------------------------------|----------------------|
| å‡†ç¡®ç‡   | \( \frac{TP + TN}{TP + FP + FN + TN} \) | å‡è¡¡æ•°æ®             |
| ç²¾ç¡®ç‡   | \( \frac{TP}{TP + FP} \)               | æ³¨é‡é¢„æµ‹è´¨é‡         |
| å¬å›ç‡   | \( \frac{TP}{TP + FN} \)               | æ³¨é‡æŸ¥å…¨ç‡           |
| F1åˆ†æ•°   | \( 2 \times \frac{Precision \times Recall}{Precision + Recall} \) | ç»¼åˆæŒ‡æ ‡             |

### 2. äº¤å‰éªŒè¯ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
**â€‹â€‹ä¼ ç»ŸéªŒè¯ vs KæŠ˜äº¤å‰éªŒè¯**
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph LR
    A[æ•°æ®] --> B[è®­ç»ƒé›†]
    A --> C[æµ‹è¯•é›†]
    
    D[æ•°æ®] --> E[æŠ˜1:æµ‹è¯•é›†]
    D --> F[æŠ˜2:æµ‹è¯•é›†]
    D --> G[æŠ˜3:æµ‹è¯•é›†]
    D --> H[...]
    
    style A fill:#f9f,stroke:#333
    style B fill:#ccf,stroke:#333
    style C fill:#fcc,stroke:#333
    style D fill:#f9f,stroke:#333
    style E fill:#fcc,stroke:#333
    style F fill:#fcc,stroke:#333
    style G fill:#fcc,stroke:#333
```
```python
# äº¤å‰éªŒè¯ç¤ºä¾‹
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

# åˆ›å»ºæ¨¡å‹
model = RandomForestClassifier()

# ä½¿ç”¨5æŠ˜äº¤å‰éªŒè¯
scores = cross_val_score(model, X, y, cv=5)

print(f"äº¤å‰éªŒè¯å¾—åˆ†: {scores}")
print(f"å¹³å‡å‡†ç¡®ç‡: {scores.mean():.2f}")
```
### 3. è¶…å‚æ•°è°ƒä¼˜ï¼šæ¨¡å‹å¾®è°ƒ
â€‹â€‹**ä¸¤ç§ä¸»è¦æ–¹æ³•â€‹â€‹ï¼š**
1. **ç½‘æ ¼æœç´¢**â€‹â€‹ï¼šå°è¯•æ‰€æœ‰å¯èƒ½çš„å‚æ•°ç»„åˆ
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

print("æœ€ä½³å‚æ•°ç»„åˆ:", grid_search.best_params_)
```
2. â€‹**éšæœºæœç´¢**â€‹â€‹ï¼šéšæœºé‡‡æ ·å‚æ•°ç»„åˆï¼Œæ›´é«˜æ•ˆ
```python
from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'n_estimators': range(50, 500, 50),
    'max_depth': range(3, 15)
}

random_search = RandomizedSearchCV(RandomForestClassifier(), 
                                 param_dist, 
                                 n_iter=20, 
                                 cv=5)
random_search.fit(X_train, y_train)
```

> **è®°ä½ï¼šæœºå™¨å­¦ä¹ ä¸æ˜¯é­”æ³•ï¼å¥½çš„æ¨¡å‹ = 70%æ•°æ®è´¨é‡ + 20%ç‰¹å¾å·¥ç¨‹ + 10%æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜**   
>> å¼€å§‹ä½ çš„æœºå™¨å­¦ä¹ ä¹‹æ—…å§ï¼å®è·µæ˜¯æœ€å¥½çš„å­¦ä¹ æ–¹æ³•ï¼Œå°è¯•è§£å†³Kaggleä¸Šçš„å…¥é—¨ç«èµ›æ¥ç§¯ç´¯ç»éªŒã€‚

## ğŸ“˜ æ¨èèµ„æºï¼š
- [Andrew Ng æœºå™¨å­¦ä¹ è¯¾ç¨‹](https://www.coursera.org/learn/machine-learning)
- [ğŸ“– ã€Šæœºå™¨å­¦ä¹ ã€‹ - å‘¨å¿—å](https://book.douban.com/subject/26708119/)
- [Kaggle](https://www.kaggle.com/)
- [UCI ML](https://archive.ics.uci.edu/)

---

# **<h3 id="3">[ğŸ”¥ é˜¶æ®µ 2ï¼šæ·±åº¦å­¦ä¹ ](https://github.com/0voice/learning-Journey-AI/tree/main/Deep%20learning)</h3>**

> ***æ·±åº¦å­¦ä¹ å…¥é—¨æŒ‡å— ğŸš€*** æ·±åº¦å­¦ä¹ å°±åƒæ•™å©´å„¿è®¤è¯†ä¸–ç•Œâ€‹â€‹ï¼š
>> **å…ˆè®¤è¯†å½¢çŠ¶ï¼ˆåŸºç¡€ç†è®ºï¼‰**ï¼Œ**å†è®¤äººè„¸ï¼ˆè®¡ç®—æœºè§†è§‰ï¼‰**ï¼Œ  
>> **ç„¶åå­¦è¯´è¯ï¼ˆNLPï¼‰**ï¼Œ**æœ€åå­¦ä¼šåˆ›ä½œï¼ˆç”Ÿæˆæ¨¡å‹ï¼‰**ã€‚

| æ–¹å‘         | æ ¸å¿ƒæŠ€æœ¯                        | å­¦ä¹ èµ„æº                             |
|--------------|---------------------------------|--------------------------------------|
| åŸºç¡€ç†è®º     | ç¥ç»ç½‘ç»œÂ·åå‘ä¼ æ’­Â·æ­£åˆ™åŒ–        | [æ·±åº¦å­¦ä¹ ](https://www.deeplearningbook.org/) |
| è®¡ç®—æœºè§†è§‰   | CNNÂ·ç›®æ ‡æ£€æµ‹Â·å›¾åƒåˆ†å‰²           | [CS231n](http://cs231n.stanford.edu/)         |
| NLP          | RNNã€Transformerã€BERTã€LLMs          | [NLPè¯¾ç¨‹](https://course.fast.ai/)  |
| ç”Ÿæˆæ¨¡å‹     | GANã€Diffusionã€ChatGPT              | [Hugging Face](https://huggingface.co/)       |



## [ç¥ç»ç½‘ç»œè¶…è¯¦ç»†å›¾è§£ï¼šå°ç™½çš„3Dæ‹†è§£æŒ‡å— ğŸ§ ](Deep%20learning/ç¥ç»ç½‘ç»œ.md)
> æƒ³è±¡ç¥ç»ç½‘ç»œå°±åƒä¸€å¥—ä¹é«˜ç§¯æœ¨å·¥å‚ï¼è¾“å…¥æ˜¯åŸæ–™ï¼Œè¾“å‡ºæ˜¯æˆå“ï¼Œéšè—å±‚å°±æ˜¯å±‚å±‚ç»„è£…æµæ°´çº¿ã€‚ä¸‹é¢å¸¦ä½ èµ°è¿›è¿™ä¸ªç¥å¥‡å·¥å‚ï¼š

### ä¸€ã€æ ¸å¿ƒç»“æ„
#### 1. æ ¸å¿ƒä¸‰ä»¶å¥—
- åƒäººè„‘ç¥ç»å…ƒç½‘ç»œï¼šè¾“å…¥å±‚ï¼ˆçœ¼ç›çœ‹ï¼‰â†’ éšè—å±‚ï¼ˆå¤§è„‘æ€è€ƒï¼‰â†’ è¾“å‡ºå±‚ï¼ˆå˜´å·´è¯´ï¼‰
- å¯è§†åŒ–ç†è§£ï¼š
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph LR
    A[è¾“å…¥æ•°æ®] --> B[ç¥ç»å…ƒ1]
    A --> C[ç¥ç»å…ƒ2]
    B --> D[è¾“å‡ºç»“æœ]
    C --> D
    style A fill:#9f9
    style B fill:#f99
    style C fill:#f99
    style D fill:#99f
```

```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph LR
    A[åŸæ–™ä»“åº“] -->|è¾“å…¥æ•°æ®| B[é›¶ä»¶åŠ å·¥çº¿]
    B --> C[ç²¾å¯†ç»„è£…çº¿]
    C --> D[è´¨æ£€åŒ…è£…çº¿]
    D --> E[æˆå“ä»“åº“]
    
    style A fill:#9f9,stroke:#333
    style B fill:#f99,stroke:#333
    style C fill:#f99,stroke:#333
    style D fill:#f99,stroke:#333
    style E fill:#99f,stroke:#333
```
- è¾“å…¥å±‚â€‹â€‹ â†’ åŸæ–™ä»“åº“ï¼ˆæ¥æ”¶åŸå§‹æ•°æ®ï¼šå¦‚å›¾åƒåƒç´ /æ–‡å­—ç¼–ç ï¼‰
- â€‹â€‹éšè—å±‚â€‹â€‹ â†’ ç»„è£…è½¦é—´ï¼ˆå¤šå±‚æµæ°´çº¿å¤„ç†ç‰¹å¾ï¼‰
- â€‹â€‹è¾“å‡ºå±‚â€‹â€‹ â†’ æˆå“ä»“åº“ï¼ˆç”Ÿæˆç»“æœï¼šå¦‚"çŒ«/ç‹—"åˆ†ç±»ï¼‰

#### 2. åå‘ä¼ æ’­â€‹â€‹
- å­¦ä¹ è¿‡ç¨‹ï¼šè€ƒè¯•åè€å¸ˆæ‰¹æ”¹è¯•å· â†’ å‘Šè¯‰ä½ å“ªé‡Œé”™äº† â†’ ä¸‹æ¬¡æ”¹è¿›
- æ•°å­¦æœ¬è´¨ï¼šä»è¾“å‡ºå±‚å€’æ¨è°ƒæ•´æ¯ä¸ªç¥ç»å…ƒçš„"é‡è¦æ€§æƒé‡"  

#### 3. æ­£åˆ™åŒ–â€‹â€‹  
- é˜²"æ­»è®°ç¡¬èƒŒ"ï¼šç»™å­¦ç”Ÿåˆ’é‡ç‚¹ï¼ˆé™ä½å¤æ‚åº¦ï¼‰ï¼Œé¿å…è€ƒè¯•æ¢é¢˜å°±æŒ‚ç§‘ï¼ˆè¿‡æ‹Ÿåˆï¼‰
- å¸¸ç”¨æ–¹æ³•ï¼šDropoutï¼ˆéšæœºå±è”½ç¥ç»å…ƒï¼‰ã€L1/L2ï¼ˆæ§åˆ¶æƒé‡æ•°å€¼ï¼‰

**ğŸ“Œ â€‹â€‹çœŸå®æ¡ˆä¾‹â€‹â€‹ï¼šäººè„¸è¯†åˆ«ç³»ç»Ÿ**
- è¾“å…¥å±‚ï¼šæ¥æ”¶128x128åƒç´ å›¾ç‰‡ï¼ˆ=16,384ä¸ªè¾“å…¥ç‚¹ï¼‰
- éšè—å±‚ï¼šå±‚å±‚æå–çœ¼ç›/é¼»å­ç­‰ç‰¹å¾
- è¾“å‡ºå±‚ï¼šåˆ¤æ–­è¿™æ˜¯å¦æ˜¯ç‰¹å®šäººç‰©

### äºŒã€ç¥ç»å…ƒï¼šå·¥å‚é‡Œçš„æ™ºèƒ½æœºå™¨äºº
æ¯ä¸ªç¥ç»å…ƒéƒ½æ˜¯å¾®å‹è®¡ç®—å•å…ƒï¼š
```python
# å•ä¸ªç¥ç»å…ƒçš„å·¥ä½œä»£ç 
def ç¥ç»å…ƒ(è¾“å…¥ä¿¡å·, æƒé‡, åç½®):
    weighted_sum = sum(è¾“å…¥ä¿¡å· * æƒé‡) + åç½®  # åŠ æƒæ±‚å’Œ
    return æ¿€æ´»å‡½æ•°(weighted_sum)           # éçº¿æ€§è½¬æ¢
```
- æƒé‡(weight)â€‹â€‹ â†’ å·¥äººç»éªŒå€¼ï¼ˆè€å·¥äººæ›´å…³æ³¨å…³é”®ç‰¹å¾ï¼‰
- â€‹â€‹åç½®(bias)â€‹â€‹ â†’ è´¨æ£€æ ‡å‡†ï¼ˆè°ƒæ•´åˆ¤æ–­æ¾ç´§åº¦ï¼‰
- â€‹â€‹æ¿€æ´»å‡½æ•°â€‹â€‹ â†’ æ ¸å¿ƒï¼è®©æœºå™¨å…·å¤‡"æ€è€ƒèƒ½åŠ›"çš„ç§˜å¯†æ­¦å™¨

**å¸¸è§æ¿€æ´»å‡½æ•°å¯¹æ¯”ï¼š**
  
| å‡½æ•°åç§°   | å·¥ä½œæ–¹å¼               | é€‚ç”¨åœºæ™¯       | å½¢è±¡æ¯”å–»         |
|------------|-----------------------|---------------|------------------|
| Sigmoid    | å‹ç¼©åˆ°0-1åŒºé—´         | æ¦‚ç‡é¢„æµ‹       | æ¸©å’Œçš„è€å¸ˆå‚…     |
| ReLU       | è´Ÿæ•°å½’é›¶ï¼Œæ­£æ•°ä¿ç•™     | 90%ç°ä»£ç½‘ç»œ    | æœæ–­çš„è´¨æ£€å‘˜ âœ…  |
| Tanh       | å‹ç¼©åˆ°-1åˆ°1åŒºé—´       | RNNç½‘ç»œ       | ä¸¥æ ¼çš„å·¥ç¨‹å¸ˆ     |

***ğŸ”¥ ä¸ºä»€ä¹ˆéœ€è¦æ¿€æ´»å‡½æ•°ï¼Ÿ***  
æ²¡æœ‰å®ƒ â†’ ç¥ç»ç½‘ç»œåªæ˜¯é«˜çº§è®¡ç®—å™¨ï¼ˆåªèƒ½å¤„ç†çº¿æ€§é—®é¢˜ï¼‰  
åŠ ä¸Šå®ƒ â†’ ç¥ç»ç½‘ç»œå˜èº«ä¸‡èƒ½è¿‘ä¼¼å™¨ï¼ˆå¯å¤„ç†ä»»æ„å¤æ‚é—®é¢˜ï¼‰  

### ä¸‰ã€è®­ç»ƒè¿‡ç¨‹ï¼šå·¥å‚å¸ˆå¾’æ•™å­¦ç³»ç»Ÿ
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
sequenceDiagram
    Master->>Apprentice: Give 1000 cat and dog images
    %% å¸ˆå‚…ç»™å­¦å¾’1000å¼ çŒ«ç‹—å›¾ç‰‡
    Apprentice->>Master: First prediction (accuracy 40%)
    %% å­¦å¾’ç¬¬ä¸€æ¬¡é¢„æµ‹(å‡†ç¡®ç‡40%)
    Master->>Apprentice: Calculate prediction error (loss function)
    %% å¸ˆå‚…è®¡ç®—é¢„æµ‹é”™è¯¯ç¨‹åº¦(æŸå¤±å‡½æ•°)
    Master->>Apprentice: Provide correction method (backpropagation)
    %% å¸ˆå‚…åå‘æŒ‡å¯¼ä¿®æ­£æ–¹æ³•(åå‘ä¼ æ’­)
    loop Repeated practice
        Apprentice->>Master: New prediction
        %% å­¦å¾’æ–°ä¸€æ¬¡é¢„æµ‹
        Master->>Apprentice: Correct weight parameters
        %% å¸ˆå‚…ä¿®æ­£æƒé‡å‚æ•°
    end
    Apprentice->>Master: Final prediction (accuracy 95%) ğŸ‘
    %% å­¦å¾’æœ€ç»ˆé¢„æµ‹(å‡†ç¡®ç‡95%) ğŸ‘
```

**å…³é”®è®­ç»ƒç»„ä»¶**
#### 1. â€‹â€‹æŸå¤±å‡½æ•°â€‹â€‹ â†’ æˆç»©å•
- åˆ†ç±»ä»»åŠ¡ï¼šäº¤å‰ç†µï¼ˆCross-Entropyï¼‰

 æŸå¤± = -Î£(çœŸå®å€¼ * log(é¢„æµ‹å€¼))
- å›å½’ä»»åŠ¡ï¼šå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
  
 æŸå¤± = Î£(é¢„æµ‹å€¼ - çœŸå®å€¼)Â² / n
#### â€‹â€‹2. ä¼˜åŒ–å™¨â€‹â€‹ â†’ æ•™å­¦æ–¹æ³•
- åŸºç¡€ç‰ˆï¼šæ¢¯åº¦ä¸‹é™
  
 æ–°æƒé‡ = æ—§æƒé‡ - å­¦ä¹ ç‡ Ã— æ¢¯åº¦
- æ™ºèƒ½ç‰ˆï¼šAdamä¼˜åŒ–å™¨ï¼ˆè‡ªåŠ¨è°ƒèŠ‚å­¦ä¹ ç‡ï¼‰
#### 3. â€‹â€‹åå‘ä¼ æ’­â€‹â€‹ â†’ é”™é¢˜åˆ†æ
- ä»è¾“å‡ºå±‚å¼€å§‹é€å±‚å›æº¯
- ç”¨é“¾å¼æ³•åˆ™è®¡ç®—å„å±‚æƒé‡éœ€è°ƒæ•´çš„ç¨‹åº¦

> ***ğŸ’¡ å­¦ä¹ ç‡å°è´´å£«ï¼š***  
> å¤ªå¤§ â†’ å­¦å¾’æµ®èºä¹±æ”¹å‚æ•°ï¼ˆéœ‡è¡ä¸æ”¶æ•›ï¼‰  
> å¤ªå° â†’ å­¦å¾’è¿›æ­¥ç¼“æ…¢ï¼ˆè®­ç»ƒé€Ÿåº¦æ…¢ï¼‰  
> ç†æƒ³å€¼ â†’ 0.001åˆ°0.1ä¹‹é—´ï¼ˆéœ€å®éªŒè°ƒæ•´ï¼‰  

### å››ã€å®æˆ˜æ¼”ç¤ºï¼šæ‰‹å†™æ•°å­—è¯†åˆ«
**ç”¨Python+Kerasæ­å»º28x28åƒç´ è¯†åˆ«ç½‘ç»œï¼š**
```python
from keras.models import Sequential
from keras.layers import Dense

# æ­å»ºæµæ°´çº¿
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(784,))) # é¦–å±‚éœ€æŒ‡å®šè¾“å…¥å°ºå¯¸
model.add(Dense(256, activation='relu'))     # éšè—å±‚2
model.add(Dense(128, activation='relu'))     # éšè—å±‚3
model.add(Dense(10, activation='softmax'))   # è¾“å‡ºå±‚(10ä¸ªæ•°å­—æ¦‚ç‡)

# é…ç½®ç”Ÿäº§çº¿
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# å¼€å§‹è®­ç»ƒ(ä½¿ç”¨MNISTæ•°æ®é›†)
model.fit(x_train, y_train, epochs=10)

# æµ‹è¯•æ•ˆæœ
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"è¯†åˆ«å‡†ç¡®ç‡: {test_acc*100:.1f}%")  # å…¸å‹ç»“æœï¼š98.2%
```

**ç½‘ç»œç»“æ„å¯è§†åŒ–ï¼š**
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
flowchart TD
    A[è¾“å…¥å±‚ 784èŠ‚ç‚¹] --> B[éšè—å±‚1 512èŠ‚ç‚¹]
    B --> C[éšè—å±‚2 256èŠ‚ç‚¹]
    C --> D[éšè—å±‚3 128èŠ‚ç‚¹]
    D --> E[è¾“å‡ºå±‚ 10èŠ‚ç‚¹]
    
    style A fill:#9f9
    style B fill:#f99
    style C fill:#f99
    style D fill:#f99
    style E fill:#99f
```

### äº”ã€ç¥ç»ç½‘ç»œç±»å‹å›¾è°±
| ç±»å‹             | ç»“æ„ç‰¹ç‚¹               | å…¸å‹åº”ç”¨          |
|------------------|------------------------|-------------------|
| å…¨è¿æ¥ç½‘ç»œ       | æ¯å±‚ç¥ç»å…ƒå…¨éƒ¨äº’è”      | åŸºç¡€åˆ†ç±»/å›å½’      |
| CNN              | å·ç§¯å±‚+æ± åŒ–å±‚ç»„åˆ       | å›¾åƒå¤„ç† âœ…        |
| RNN              | å¸¦æ—¶é—´å¾ªç¯è¿æ¥          | æ–‡æœ¬/è¯­è¨€         |
| Transformer      | è‡ªæ³¨æ„åŠ›æœºåˆ¶            | NLPä»»åŠ¡ âœ…        |


**ğŸš€ å‡çº§æŠ€å·§ï¼š**

- æ·»åŠ Dropoutå±‚ï¼šéšæœºåœå·¥éƒ¨åˆ†æµæ°´çº¿ï¼ˆé˜²è¿‡æ‹Ÿåˆï¼‰
- æ‰¹æ ‡å‡†åŒ–(BatchNorm)ï¼šç»Ÿä¸€é›¶ä»¶è§„æ ¼ï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰
- è¿ç§»å­¦ä¹ ï¼šç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è€å¸ˆå‚…ï¼ˆå¦‚ResNet/VGGï¼‰

> ç¥ç»ç½‘ç»œå°±åƒä¹é«˜å·¥å‚â€”â€”é€šè¿‡ç®€å•çš„é›¶ä»¶ï¼ˆç¥ç»å…ƒï¼‰ç»„åˆï¼Œæœ€ç»ˆèƒ½å»ºé€ å‡ºæ™ºèƒ½å¸å›½å¤§å¦ï¼  
> ç°åœ¨å°±åœ¨**[Google Colab](https://colab.research.google.com/)**åŠ¨æ‰‹æ­å»ºä½ çš„ç¬¬ä¸€ä¸ªç½‘ç»œå§ï¼

### ğŸ“š â€‹â€‹å­¦ä¹ èµ„æºâ€‹â€‹ï¼š
ã€Š[æ·±åº¦å­¦ä¹ ](https://github.com/exacity/deeplearningbook-chinese/tree/master)ã€‹(èŠ±ä¹¦) - AIé¢†åŸŸçš„"åœ£ç»"ï¼Œé…å¥¶èŒ¶æ…¢æ…¢å•ƒæ•ˆæœæ›´ä½³ â˜•

## [äºŒã€è®¡ç®—æœºè§†è§‰ï¼šæœºå™¨çš„"çœ¼ç›" 0.0](Deep%20learning/è®¡ç®—æœºè§†è§‰.md)  
> è®¡ç®—æœºè§†è§‰è¶…å…¨è§£æï¼šä»åƒç´ åˆ°æ™ºèƒ½è¯†åˆ«çš„å¥‡å¦™ä¹‹æ—… ğŸŒŸ  

### 1. è§†è§‰ä¸–ç•Œçš„æ•°å­—å¯†ç   

è®¡ç®—æœºè§†è§‰çš„ç¬¬ä¸€æ­¥æ˜¯æŠŠå›¾åƒè½¬åŒ–ä¸ºæ•°å­—è¯­è¨€ï¼š
```python
import numpy as np
from PIL import Image

# åŠ è½½ä¸€å¼ çŒ«å’ªå›¾ç‰‡
image = Image.open("cat.jpg")
pixel_data = np.array(image)

print(f"å›¾ç‰‡å°ºå¯¸: {pixel_data.shape}")  # ä¾‹å¦‚ (480, 640, 3)
print("å·¦ä¸Šè§’åƒç´ å€¼:", pixel_data[0, 0])  # ä¾‹å¦‚ [255, 200, 150]
```
åƒç´ çŸ©é˜µæ­ç§˜â€‹â€‹ï¼š
```
RGBé€šé“è¯¦è§£ï¼š
[ R: 255, G: 200, B: 150 ] â†’ äº®æ©™çº¢è‰²
```

**é«˜çº§æŠ€å·§ï¼šé€šè¿‡ä»¥ä¸‹æ“ä½œå¢å¼ºå›¾åƒï¼š**
- Grayscale = 0.299*R + 0.587*G + 0.114*B (ç°åº¦è½¬æ¢)

- Histogram equalization (ç›´æ–¹å›¾å‡è¡¡åŒ–æé«˜å¯¹æ¯”åº¦)

### 2. ç‰¹å¾å·¥ç¨‹ï¼šæœºå™¨å¦‚ä½•"çœ‹æ‡‚"å›¾åƒ
è®¡ç®—æœºéœ€è¦æå–å›¾åƒçš„ç‰¹å¾æ¨¡å¼ï¼š  

| ä¼ ç»Ÿæ–¹æ³•          | æ·±åº¦å­¦ä¹ æ–¹æ³•       | ç‰¹ç‚¹å¯¹æ¯”                          |
|-------------------|--------------------|----------------------------------|
| SIFTæ—‹è½¬ä¸å˜ç‰¹å¾   | CNNå·ç§¯æ ¸          | ä¼ ç»Ÿæ–¹æ³•éœ€æ‰‹å·¥è®¾è®¡ï¼ŒCNNè‡ªåŠ¨å­¦ä¹     |
| HOGè¡Œäººæ£€æµ‹ç‰¹å¾    | æ³¨æ„åŠ›æœºåˆ¶         | HOGåªå¯¹ç‰¹å®šç›®æ ‡æœ‰æ•ˆï¼ŒCNNæ³›åŒ–å¼º    |
| LBPçº¹ç†ç‰¹å¾        | ç«¯åˆ°ç«¯ç‰¹å¾æå–     | ä¼ ç»Ÿæ–¹æ³•è®¡ç®—å¿«ï¼ŒCNNç²¾åº¦é«˜         |  

**å·ç§¯æ“ä½œå¯è§†åŒ–ï¼š**
```python
åŸå§‹å›¾åƒï¼š [1 1 1 0 0]
å·ç§¯æ ¸ï¼š   [1 0 -1]
ç»“æœï¼š     [ (1 * 1)+(1 * 0)+(1*(-1)) = 0 ]
           [ (1 * 1)+(1 * 0)+(0*(-1)) = 1 ] â†’ è¾¹ç¼˜æ£€æµ‹ï¼
```
### 3. CNNï¼šè§†è§‰å¤„ç†çš„é©å‘½è€…
å·ç§¯ç¥ç»ç½‘ç»œå·¥ä½œåŸç†å…¨è§£æï¼š
```mermaid
graph TD
    A[è¾“å…¥å›¾åƒ 224x224x3] --> B[å·ç§¯å±‚1]
    B --> C[ReLUæ¿€æ´»]
    C --> D[æœ€å¤§æ± åŒ–]
    D --> E[å·ç§¯å±‚2]
    E --> F[ReLUæ¿€æ´»]
    F --> G[å…¨å±€æ± åŒ–]
    G --> H[å…¨è¿æ¥å±‚]
    H --> I[åˆ†ç±»è¾“å‡º]
    
    style A fill:#9f9
    style B fill:#f99
    style C fill:#ff9
    style D fill:#99f
    style I fill:#99f
```
**æ ¸å¿ƒç»„ä»¶è¯¦è§£â€‹â€‹ï¼š**

â€‹â€‹1. å·ç§¯å±‚â€‹â€‹ï¼š
- ä½¿ç”¨3x3æ»¤æ³¢å™¨æ‰«æå›¾åƒ
- æå–å±€éƒ¨ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ç­‰ï¼‰
- å¤šä¸ªæ»¤æ³¢å™¨ç»„åˆæ£€æµ‹å¤æ‚ç‰¹å¾
  
â€‹â€‹2. â€‹â€‹æ± åŒ–å±‚â€‹â€‹ï¼š
- é™ç»´æ“ä½œï¼ˆé€šå¸¸2x2åŒºåŸŸå–æœ€å¤§å€¼ï¼‰
- å¢å¼ºä½ç½®ä¸å˜æ€§
- ä¿ç•™é‡è¦ç‰¹å¾

â€‹â€‹3. å®æˆ˜ä»£ç â€‹â€‹ï¼ˆPyTorchç‰ˆï¼‰ï¼š
```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3) # 3é€šé“è¾“å…¥, 32ä¸ªå·ç§¯æ ¸, 3x3å¤§å°
        self.pool = nn.MaxPool2d(2, 2)  # 2x2æ± åŒ–
        self.conv2 = nn.Conv2d(32, 64, 3)
        self.fc1 = nn.Linear(64 * 54 * 54, 10) # å…¨è¿æ¥å±‚
        
    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # å±•å¹³
        x = self.fc1(x)
        return x
```

### 4. ç»å…¸ç½‘ç»œæ¶æ„
è®¡ç®—æœºè§†è§‰çš„é‡Œç¨‹ç¢‘æ¨¡å‹ï¼š
| æ¨¡å‹             | åˆ›æ–°ç‚¹               | è´¡çŒ®                      | åº”ç”¨åœºæ™¯              |
|------------------|----------------------|--------------------------|-----------------------|
| AlexNet (2012)   | é¦–ä¸ªæ·±åº¦CNN          | ImageNetå† å†›             | é€šç”¨åˆ†ç±»             |
| VGG (2014)       | ç»Ÿä¸€3x3å·ç§¯          | ç»“æ„ç®€æ´é«˜æ•ˆ              | ç‰¹å¾æå–             |
| ResNet (2015)    | æ®‹å·®è¿æ¥             | è§£å†³æ¢¯åº¦æ¶ˆå¤±              | è¶…æ·±åº¦ç½‘ç»œ(1000+å±‚)  |
| YOLO (2016)      | å•æ¬¡æ£€æµ‹             | å®æ—¶ç›®æ ‡æ£€æµ‹              | è‡ªåŠ¨é©¾é©¶ã€è§†é¢‘ç›‘æ§   |
| U-Net (2015)     | ç¼–ç -è§£ç ç»“æ„        | ç²¾ç»†å›¾åƒåˆ†å‰²              | åŒ»ç–—å½±åƒ             |

### 5. è®¡ç®—æœºè§†è§‰åº”ç”¨å…¨æ™¯å›¾
1. ç›®æ ‡æ£€æµ‹ï¼šå®šä½ä¸è¯†åˆ«
â€‹â€‹YOLOâ€‹â€‹ï¼ˆYou Only Look Onceï¼‰ç®—æ³•ï¼š
```python
# ä½¿ç”¨é¢„è®­ç»ƒYOLOv5æ¨¡å‹æ£€æµ‹ç‰©ä½“
import torch
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # åŠ è½½æ¨¡å‹
results = model('street.jpg')  # æ¨ç†
results.print()  # æ˜¾ç¤ºç»“æœ
results.save()   # ä¿å­˜æ ‡æ³¨å›¾åƒ
```
**å…¸å‹è¾“å‡º:**
```
æ£€æµ‹ç»“æœ: 
    car: ç½®ä¿¡åº¦0.87 ä½ç½® [x1=320, y1=210, x2=580, y2=390]
    person: ç½®ä¿¡åº¦0.92 ä½ç½® [x1=150, y1=300, x2=220, y2=480]
```
2. å›¾åƒåˆ†å‰²ï¼šåƒç´ çº§è¯†åˆ«
åŒ»ç–—å›¾åƒåˆ†å‰²ç¤ºä¾‹ï¼š
```mermaid
graph LR
    A[CTæ‰«æå›¾] --> B[U-Netåˆ†å‰²]
    B --> C[è‚ºéƒ¨åŒºåŸŸæ ‡è®°]
    C --> D[ç–¾ç—…åŒºåŸŸåˆ†æ]
    style A fill:#9f9
    style C fill:#f99
    style D fill:#99f
```
3. å›¾åƒç”Ÿæˆï¼šåˆ›é€ æ–°å†…å®¹
â€‹â€‹GANå¯¹æŠ—ç”Ÿæˆç½‘ç»œâ€‹â€‹ï¼š
```mermaid
graph LR
    A[éšæœºå™ªå£°] --> B[ç”Ÿæˆå™¨]
    B --> C[ç”Ÿæˆå›¾åƒ]
    C --> D[é‰´åˆ«å™¨]
    D -->|çœŸ/å‡åˆ¤æ–­| B
    style A fill:#9f9
    style B fill:#f99
    style C fill:#ff9
    style D fill:#99f
```
**ä½¿ç”¨GANçš„åº”ç”¨ï¼š**
```python
from stylegan2 import generate_faces
generated_images = generate_faces(num=4)  # ç”Ÿæˆ4å¼ äººè„¸
```

### 6. è®¡ç®—æœºè§†è§‰å·¥å…·ç®±
å®Œæ•´å¼€å‘æµç¨‹ï¼š  

â€‹â€‹1. æ•°æ®å¤„ç†
```python
import albumentations as A  # å¼ºå¤§çš„æ•°æ®å¢å¼ºåº“

transform = A.Compose([
    A.RandomRotate30(),       # éšæœºæ—‹è½¬
    A.HorizontalFlip(p=0.5), # æ°´å¹³ç¿»è½¬
    A.RGBShift(),             # é¢œè‰²åç§»
    A.Normalize()             # æ ‡å‡†åŒ–
])
```

â€‹â€‹2. è¿ç§»å­¦ä¹ â€‹â€‹ï¼ˆåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
```python
from torchvision import models

# åŠ è½½é¢„è®­ç»ƒResNet
model = models.resnet50(pretrained=True)

# æ›¿æ¢æœ€åä¸€å±‚
model.fc = nn.Linear(2048, 10)  # é€‚é…æ–°ä»»åŠ¡çš„10åˆ†ç±»
```

â€‹â€‹3. æ¨¡å‹éƒ¨ç½²
```
éƒ¨ç½²è·¯å¾„ï¼š
å¼€å‘ç¯å¢ƒè®­ç»ƒ â†’ è½¬æ¢ä¸ºONNXæ ¼å¼ â†’ TensorRTåŠ é€Ÿ â†’ éƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡
```
### 7. å­¦ä¹ è·¯çº¿å›¾
```mermaid
flowchart TD
    A[PythonåŸºç¡€] --> B[OpenCVå›¾åƒå¤„ç†]
    B --> C[PyTorch/TensorFlow]
    C --> D[ç»å…¸CNNå®ç°]
    D --> E[ç›®æ ‡æ£€æµ‹å®æˆ˜]
    E --> F[å›¾åƒåˆ†å‰²é¡¹ç›®]
    F --> G[å·¥ä¸šåº”ç”¨éƒ¨ç½²]
    
    style A fill:#9f9,stroke:#333
    style B fill:#f99,stroke:#333
    style C fill:#99f,stroke:#333
    style D fill:#ff9,stroke:#333
    style E fill:#f9f,stroke:#333
    style F fill:#9ff,stroke:#333
    style G fill:#6f6,stroke:#333
```

**è®¡ç®—æœºè§†è§‰æ­£åœ¨æ”¹å˜ä¸–ç•Œï¼š**

- ğŸš— è‡ªåŠ¨é©¾é©¶æ±½è½¦å®æ—¶æ„ŸçŸ¥ç¯å¢ƒ
- ğŸ¥ AIåŒ»ç–—å½±åƒè¾…åŠ©è¯Šæ–­
- ğŸ›’ é›¶å”®æ— äººç»“è´¦ç³»ç»Ÿ
- ğŸ¨ AIè‰ºæœ¯åˆ›ä½œå·¥å…·

**åŠ¨æ‰‹å®è·µå»ºè®®ï¼š**

- ä»OpenCVåŸºç¡€æ“ä½œå¼€å§‹
- å¤ç°ç»å…¸è®ºæ–‡ï¼ˆå¦‚ResNetï¼‰
- å‚åŠ Kaggleè®¡ç®—æœºè§†è§‰æ¯”èµ›
- å°è¯•Gradioæ„å»ºè§†è§‰åº”ç”¨æ¼”ç¤º

> ***"è®¡ç®—æœºä¸æ˜¯å¤©ç”Ÿèƒ½çœ‹è§çš„ï¼Œæˆ‘ä»¬é€šè¿‡ç®—æ³•èµ‹äºˆå®ƒè§†è§‰è®¤çŸ¥èƒ½åŠ›ã€‚æ¯ä¸€è¡Œä»£ç éƒ½æ˜¯æœºå™¨è§†è§‰ç³»ç»Ÿçš„ä¸€æ ¹ç¥ç»å…ƒ"***

### ğŸ¥ â€‹â€‹å­¦ä¹ èµ„æºâ€‹â€‹ï¼š
[æ–¯å¦ç¦CS231nè¯¾ç¨‹](https://www.bilibili.com/video/BV1nJ411z7fe/)ï¼ˆBç«™æœ‰ä¸­æ–‡ç‰ˆï¼‰â†’ çœ‹5èŠ‚è¯¾å°±èƒ½è‡ªå·±å†™å›¾åƒè¯†åˆ«ç¨‹åºï¼

## [ä¸‰ã€NLPï¼šè®©æœºå™¨æ‡‚äººè¯ ğŸ’¬](Deep%learning/nlp.md)
>  **è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å…¨æ™¯è§£æï¼šä»æ–‡å­—åˆ°æ™ºèƒ½çš„è¿›åŒ–ä¹‹è·¯ ğŸ“š**
>> ***"äººç±»åˆ›é€ è¯­è¨€æ¥ç†è§£ä¸–ç•Œï¼Œç°åœ¨æˆ‘ä»¬åœ¨æ•™æœºå™¨ç†è§£äººç±»è¯­è¨€" - NLPç ”ç©¶è€…çš„ä½¿å‘½***

### ä¸€ã€NLPåŸºç¡€ï¼šè®©æœºå™¨"è¯†å­—"çš„ä¸‰æ­¥æ³•
**1. åˆ†è¯ï¼šè¯­è¨€çš„åŸºæœ¬æ‹†è§£**
```python
import jieba  # ä¸­æ–‡åˆ†è¯åº“

text = "è‡ªç„¶è¯­è¨€å¤„ç†è®©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€"
words = jieba.cut(text)

print("åˆ†è¯ç»“æœ:", "/".join(words))
# è¾“å‡º: è‡ªç„¶/è¯­è¨€/å¤„ç†/è®©/è®¡ç®—æœº/ç†è§£/äººç±»/è¯­è¨€
```
åˆ†è¯æŠ€æœ¯å¯¹æ¯”â€‹â€‹ï¼š
| è¯­è¨€   | åˆ†è¯æŠ€æœ¯       | ç‰¹ç‚¹                     |
|--------|----------------|--------------------------|
| è‹±è¯­   | ç©ºæ ¼åˆ‡åˆ†       | ç®€å•ç›´æ¥                 |
| ä¸­æ–‡   | Jieba/HanLP    | éœ€ç»“åˆè¯å…¸å’Œè§„åˆ™         |
| æ—¥è¯­   | MeCab          | å¤æ‚çš„åŠ©è¯åˆ†ç¦»           |

**2. è¯æ€§æ ‡æ³¨ï¼šè¯è¯­èº«ä»½è¯†åˆ«**
```
å¥å­: "æˆ‘çˆ±ç¼–ç¨‹"
åˆ†æ:
    æˆ‘/ä»£è¯  çˆ±/åŠ¨è¯  ç¼–ç¨‹/åè¯
```

**3. å¥æ³•åˆ†æï¼šè¯­è¨€ç»“æ„è§£æ**
```mermaid
graph TD
    A[æˆ‘] --> B[çˆ±]
    B --> C[ç¼–ç¨‹]
    style A fill:#f99
    style B fill:#9f9
    style C fill:#99f
```

### äºŒã€è¯è¡¨ç¤ºé©å‘½ï¼šä»ç¬¦å·åˆ°æ„ä¹‰
**1. ä¼ ç»Ÿæ–¹æ³•ï¼šç‹¬çƒ­ç¼–ç (One-Hot)**
```python
è¯å…¸: ["apple", "banana", "orange"]
ç¼–ç :
    apple: [1, 0, 0]
    banana: [0, 1, 0]
    orange: [0, 0, 1]
```
**ç¼ºé™·**â€‹â€‹ï¼šæ— æ³•è¡¨è¾¾è¯ä¹‰å…³ç³»ï¼Œç»´åº¦ç¾éš¾

**2. è¯åµŒå…¥(Word Embedding)ï¼šè¯­ä¹‰ç¼–ç **

ä½¿ç”¨ç¥ç»ç½‘ç»œå°†è¯æ˜ å°„åˆ°ä½ç»´ç©ºé—´ï¼š
```python
from gensim.models import Word2Vec

# è®­ç»ƒè¯å‘é‡æ¨¡å‹
sentences = [["è‡ªç„¶", "è¯­è¨€", "å¤„ç†"], ["æœºå™¨", "å­¦ä¹ ", "ç®—æ³•"]]
model = Word2Vec(sentences, vector_size=100, window=5, min_count=1)

# è·å–è¯å‘é‡
vector = model.wv["è¯­è¨€"]
print(f"è¯­è¨€'çš„è¯å‘é‡ç»´åº¦: {vector.shape}")  # (100,)

# è®¡ç®—ç›¸ä¼¼åº¦
similarity = model.wv.similarity("è¯­è¨€", "å¤„ç†")
print(f"è¯­è¨€'ä¸'å¤„ç†'çš„è¯­ä¹‰ç›¸ä¼¼åº¦: {similarity:.2f}")
```
**3. è¯å‘é‡é­”æ³•ï¼šè¯­ä¹‰ä»£æ•°**
```
vec(å›½ç‹) - vec(ç”·äºº) + vec(å¥³äºº) â‰ˆ vec(å¥³ç‹)
vec(å·´é») - vec(æ³•å›½) + vec(æ—¥æœ¬) â‰ˆ vec(ä¸œäº¬)
```
### ä¸‰ã€NLPæ ¸å¿ƒæŠ€æœ¯æ¼”è¿›å²
```mermaid
timeline
    title NLPæŠ€æœ¯çš„è¿›åŒ–è·¯çº¿
    1980å¹´ä»£ ï¼š è§„åˆ™ä¸è¯å…¸
    2000å¹´ä»£ ï¼š ç»Ÿè®¡æœºå™¨å­¦ä¹ 
    2013å¹´ ï¼š Word2Vecè¯å‘é‡
    2015å¹´ ï¼š RNN/LSTMåºåˆ—æ¨¡å‹
    2017å¹´ ï¼š Transformeré©å‘½
    2018å¹´ ï¼š BERTé¢„è®­ç»ƒæ¨¡å‹
    2020å¹´ ï¼š GPT-3å·¨é‡æ¨¡å‹
    2023å¹´ ï¼š å¤§è¯­è¨€æ¨¡å‹(LLM)æ—¶ä»£
```
**1. RNN/LSTMï¼šè®°å¿†å¢å¼ºç½‘ç»œ**
```mermaid
graph LR
    A[t] --> B[RNNå•å…ƒ]
    B --> C[t+1]
    C --> D[RNNå•å…ƒ]
    D --> E[è¾“å‡º]
    style A fill:#9f9
    style B fill:#f99
    style C fill:#ff9
    style D fill:#f99
    style E fill:#99f
```
**åº”ç”¨åœºæ™¯**â€‹â€‹ï¼šæ–‡æœ¬ç”Ÿæˆã€æƒ…æ„Ÿåˆ†æ

**2. Transformerï¼šæ³¨æ„åŠ›æœºåˆ¶é©å‘½**
**â€‹â€‹æ ¸å¿ƒåˆ›æ–°â€‹â€‹**ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶
```
å¥å­: "è¿™åªè‹¹æœæ‰‹æœºå¾ˆè´µ"
æ¨¡å‹å…³æ³¨:
    "è‹¹æœ" -> 60%å…³æ³¨"æ‰‹æœº", 30%å…³æ³¨"è´µ"
    "è´µ" -> 70%å…³æ³¨"è‹¹æœ", 25%å…³æ³¨"æ‰‹æœº"
```
**3. BERTï¼šåŒå‘ç†è§£**  

ä¸ä¼ ç»Ÿæ¨¡å‹çš„å¯¹æ¯”:
```mermaid
graph LR
    A[åŸå§‹æ–‡æœ¬] --> B[å•å‘æ¨¡å‹]
    A --> C[BERTæ¨¡å‹]
    B --> D[ä»…èƒ½åˆ©ç”¨ä¸Šæ–‡]
    C --> E[åŒæ—¶åˆ©ç”¨ä¸Šä¸‹æ–‡]
    
    style A fill:#9f9
    style B fill:#f99
    style C fill:#f99
    style D fill:#99f
    style E fill:#99f
```

### å››ã€ç°ä»£NLPå››å¤§åº”ç”¨æ”¯æŸ±
**1. æ–‡æœ¬åˆ†ç±»ä¸æƒ…æ„Ÿåˆ†æ**
```python
from transformers import pipeline

# ä½¿ç”¨é¢„è®­ç»ƒæƒ…æ„Ÿåˆ†ææ¨¡å‹
classifier = pipeline("sentiment-analysis")
result = classifier("è¿™å®¶é¤å…çš„æœåŠ¡å¤ªæ£’äº†ï¼Œé£Ÿç‰©ä¹Ÿå¾ˆç¾å‘³ï¼")

print(result)  
# [{'label': 'POSITIVE', 'score': 0.998}]
```

**2. æœºå™¨ç¿»è¯‘ï¼šæ‰“ç ´è¯­è¨€å£å’**
```
ç¿»è¯‘æµç¨‹ï¼š
ä¸­æ–‡ â†’ ç¼–ç å™¨ â†’ è¯­ä¹‰å‘é‡ â†’ è§£ç å™¨ â†’ è‹±æ–‡
```

**å¤šè¯­è¨€ç¿»è¯‘å®æˆ˜**
```python
from transformers import MarianMTModel, MarianTokenizer

# ä¸­è¯‘è‹±
model_name = "Helsinki-NLP/opus-mt-zh-en"
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)

text = "è‡ªç„¶è¯­è¨€å¤„ç†æ­£åœ¨æ”¹å˜ä¸–ç•Œ"
translated = model.generate(**tokenizer(text, return_tensors="pt"))
output = tokenizer.decode(translated[0], skip_special_tokens=True)

print(output)  # "Natural language processing is changing the world"
```

**3. é—®ç­”ç³»ç»Ÿï¼šçŸ¥è¯†æ£€ç´¢ä¸“å®¶**
â€‹â€‹æ¶æ„å›¾â€‹â€‹ï¼š
```python
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[é—®é¢˜è§£æ]
    B --> C[çŸ¥è¯†åº“æ£€ç´¢]
    C --> D[ç­”æ¡ˆç”Ÿæˆ]
    D --> E[å›ç­”è¾“å‡º]
    
    style A fill:#9f9
    style E fill:#99f
```
**4. æ–‡æœ¬ç”Ÿæˆï¼šæœºå™¨çš„åˆ›ä½œèƒ½åŠ›**  

GPTç³»åˆ—åˆ›ä½œç¤ºä¾‹ï¼š
```python
from transformers import GPT2LMHeadModel, GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

input_text = "åœ¨æœªæ¥çš„ä¸–ç•Œé‡Œï¼Œäººå·¥æ™ºèƒ½"
input_ids = tokenizer.encode(input_text, return_tensors="pt")

# ç”Ÿæˆæ–‡æœ¬
output = model.generate(
    input_ids, 
    max_length=100,
    num_return_sequences=1
)

print(tokenizer.decode(output[0], skip_special_tokens=True))
```

***è¾“å‡ºç¤ºä¾‹*â€‹â€‹**  

"åœ¨æœªæ¥çš„ä¸–ç•Œé‡Œï¼Œäººå·¥æ™ºèƒ½å°†æˆä¸ºäººç±»æœ€å¼ºå¤§çš„åŠ©æ‰‹ã€‚å®ƒä»¬ä¸ä»…èƒ½å¤„ç†å¤æ‚çš„è®¡ç®—ä»»åŠ¡ï¼Œè¿˜èƒ½åˆ›é€ ä»¤äººæƒŠå¹çš„è‰ºæœ¯ä½œå“ï¼Œç”šè‡³å¸®åŠ©ç§‘å­¦å®¶è§£å†³æ°”å€™å˜åŒ–ç­‰å…¨çƒæ€§é—®é¢˜..."

### äº”ã€NLPå®æˆ˜å·¥å…·ç®±
**1. ç°ä»£NLPå¼€å‘æ ˆ**
| å·¥å…·ç±»å‹         | ä»£è¡¨å·¥å…·               | ç”¨é€”                  |
|------------------|------------------------|-----------------------|
| åŸºç¡€åº“           | NLTK, SpaCy           | æ–‡æœ¬é¢„å¤„ç†            |
| æ·±åº¦å­¦ä¹ æ¡†æ¶     | PyTorch, TensorFlow    | æ¨¡å‹æ„å»º              |
| é¢„è®­ç»ƒæ¨¡å‹åº“     | Hugging Face           | ä¸Šåƒç§é¢„è®­ç»ƒæ¨¡å‹      |
| å¯è§†åŒ–           | TensorBoard            | è®­ç»ƒè¿‡ç¨‹ç›‘æ§          |

**2. Hugging Faceä½¿ç”¨ç¤ºä¾‹**
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨
model_name = "bert-base-chinese"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# æ–‡æœ¬å¤„ç†
inputs = tokenizer("NLPè®©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€", return_tensors="pt")

# æ¨¡å‹æ¨ç†
outputs = model(**inputs)
```

### å…­ã€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ä»£
**å¤§æ¨¡å‹å››å±‚ç»“æ„ï¼š**
```mermaid
graph TD
    A[åŸºç¡€å¤§æ¨¡å‹] --> B[é¢†åŸŸå¾®è°ƒ]
    B --> C[æç¤ºå·¥ç¨‹]
    C --> D[åº”ç”¨é›†æˆ]
    
    style A fill:#9f9
    style B fill:#f99
    style C fill:#99f
    style D fill:#ff9
```
**ChatGPTç±»ç³»ç»Ÿå·¥ä½œåŸç†**ï¼š
```
è¾“å…¥ -> æ–‡æœ¬ç¼–ç  -> å¤§è¯­è¨€æ¨¡å‹ -> æ–‡æœ¬è§£ç  -> è¾“å‡º
                     â†‘
              äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ 
```

### ä¸ƒã€å­¦ä¹ è·¯çº¿æŒ‡å—
```mermaid
flowchart LR
    A[PythonåŸºç¡€] --> B[æ–‡æœ¬å¤„ç†]
    B --> C[åŸºç¡€ç®—æ³•]
    C --> D[RNN/Transformer]
    D --> E[é¢„è®­ç»ƒæ¨¡å‹]
    E --> F[åº”ç”¨å¼€å‘]
    
    style A fill:#9f9,stroke:#333
    style B fill:#f99,stroke:#333
    style C fill:#99f,stroke:#333
    style D fill:#ff9,stroke:#333
    style E fill:#f9f,stroke:#333
    style F fill:#6f6,stroke:#333
```

**ğŸ“ƒ æ¨èå­¦ä¹ è·¯å¾„**â€‹â€‹ï¼š

1. æŒæ¡Pythonå’ŒåŸºç¡€æ–‡æœ¬å¤„ç†
2. å­¦ä¹ Word2Vecå’ŒTextCNN
3. æ·±å…¥ç†è§£Transformeræ¶æ„
4. ä½¿ç”¨Hugging Faceå®ç°BERT/GPT
5. å¼€å‘å®é™…NLPåº”ç”¨ï¼š
- æ™ºèƒ½å®¢æœæœºå™¨äºº
- æ–°é—»è‡ªåŠ¨æ‘˜è¦ç³»ç»Ÿ
- æ³•å¾‹æ–‡ä¹¦åˆ†æå·¥å…·

> ***"è‡ªç„¶è¯­è¨€å¤„ç†ä¸ä»…æ˜¯æŠ€æœ¯æŒ‘æˆ˜ï¼Œæ›´æ˜¯äººç±»ç†è§£è‡ªèº«æ€ç»´æ–¹å¼çš„çª—å£" - NLPå…ˆé©±çš„æ€è€ƒ***
>> *ç°åœ¨å°±å¼€å§‹ä½ çš„[NLP](https://mofanpy.com/tutorials/machine-learning/nlp/intro-w2v)ä¹‹æ—…å§ï¼ä»è®­ç»ƒç¬¬ä¸€ä¸ªè¯å‘é‡æ¨¡å‹åˆ°æ„å»ºèŠå¤©æœºå™¨äººï¼Œæ¯ä¸€æ­¥éƒ½åœ¨æ‹‰è¿‘äººä¸æœºå™¨çš„è·ç¦»ã€‚ğŸš€*

## å››ã€ç”Ÿæˆæ¨¡å‹ï¼šæœºå™¨çš„"æƒ³è±¡åŠ›" ğŸ¨  
**ä¸‰å¤§åˆ›ä½œå¼•æ“â€‹â€‹ï¼š**
| æŠ€æœ¯        | ä»£è¡¨ä½œ       | åˆ›ä½œèƒ½åŠ›                     |
|-------------|-------------|-----------------------------|
| GAN         | äººè„¸ç”Ÿæˆ     | å›¾åƒç”Ÿæˆ/æ¢è„¸                |
| Diffusion   | DALLE 2     | æ–‡ç”Ÿå›¾ï¼ˆè¾“å…¥"æ˜Ÿç©ºä¸‹çš„ç†ŠçŒ«"å‡ºå›¾ï¼‰ |
| LLMs        | ChatGPT     | å†™è¯—/ç¼–ç /èŠäººç”Ÿ             |

**GANå·¥ä½œåŸç†â€‹â€‹ï¼š**
```mermaid
%% é“¾è¡¨/æ ‘/å›¾ - ä½¿ç”¨Mermaidç»˜åˆ¶
graph LR
    A[ç”Ÿæˆå™¨] -->|ä¼ªé€ åç”»| B[é‰´åˆ«å™¨]
    B -->|é‰´åˆ«çœŸä¼ª| A
    style A fill:#f9f
    style B fill:#9ff
```
- ç”Ÿæˆå™¨ï¼šåƒé€ å‡å¸çš„å›¢é˜Ÿ
- é‰´åˆ«å™¨ï¼šåƒé“¶è¡ŒéªŒé’æœº
- åŒæ–¹å¯¹æŠ—æå‡ï¼Œç›´åˆ°å‡å¸æ— æ³•è¢«è¯†åˆ«

### ğŸ’¬ â€‹â€‹å­¦ä¹ èµ„æºâ€‹â€‹ï¼š
[Hugging Faceå¹³å°](https://huggingface.co/)ï¼ˆAIç•ŒGitHubï¼‰â†’ ç›´æ¥åœ¨çº¿ä½“éªŒStable Diffusionç”Ÿæˆå›¾ç‰‡ï¼

> **ğŸ’¡ â€‹â€‹å…³é”®æç¤º**â€‹â€‹ï¼šæ·±åº¦å­¦ä¹ â‰ é­”æ³•ï¼å…ˆæŒæ¡åŸºç¡€ç†è®ºå†æ”»å…·ä½“æ–¹å‘ï¼Œé‡åˆ°å…¬å¼åˆ«æ€•â†’å…ˆè·‘é€šä»£ç å†å›å¤´ç†è§£ç†è®ºæ•ˆæœæ›´ä½³ï¼

---

# **<h3 id="4">[ğŸ¯ é˜¶æ®µ 3ï¼šå·¥å…·ä¸å®è·µ](https://github.com/0voice/learning-Journey-AI/tree/main/tools)</h3>**

æœ¬ç« æ˜¯AIå­¦ä¹ çš„åŸºç¡€å·¥å…·,è¿™é‡Œåˆ—å‡ºäº†ä»**æ¡†æ¶ã€æ•°æ®å¤„ç†ã€æ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€å¼ºåŒ–å­¦ä¹ åˆ°æ¨¡å‹ä¼˜åŒ–ã€MLOpså’Œç›‘æ§**ç­‰æ–¹é¢çš„å¸¸ç”¨å·¥å…·ã€‚  

***æ‰€æœ‰å·¥å…·çš„é“¾æ¥è‹¥è¿‡æœŸè¯·è”ç³»æˆ‘è¿›è¡Œè¡¥é“¾***  

ä½ å¯ä»¥æ ¹æ®ä½ çš„éœ€æ±‚é€‰æ‹©å¯¹åº”æ–¹å‘æ–‡ä»¶ä¸­åˆé€‚çš„å·¥å…·è¿›è¡Œå­¦ä¹ å’Œä½¿ç”¨ã€‚  

**ä¸‹é¢æ˜¯å¸¸è§çš„AIæ–¹å‘å­¦ä¹ å·¥å…·**
1. [Nebullvm](https://github.com/nebuly-ai/optimate) - æ˜“äºä½¿ç”¨çš„åº“ï¼Œé€šè¿‡å¤šä¸ªæ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨æå‡æ·±åº¦å­¦ä¹ æ¨ç†æ€§èƒ½ã€‚
2. [Netron](https://github.com/lutzroeder/netron) - ç”¨äºæ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯è§†åŒ–å·¥å…·ã€‚
3. [Jupyter Notebook](http://jupyter.org) - åŸºäºç½‘é¡µçš„äº¤äº’å¼è®¡ç®—ç¯å¢ƒï¼Œç”¨äºç¬”è®°æœ¬ç¼–ç¨‹ã€‚ 
4. [TensorBoard](https://github.com/tensorflow/tensorboard) - TensorFlow çš„å¯è§†åŒ–å·¥å…·åŒ…ã€‚  
5. [Visual Studio Tools for AI](https://www.microsoft.com/en-us/research/project/visual-studio-code-tools-ai/) - å¼€å‘ã€è°ƒè¯•å’Œéƒ¨ç½²æ·±åº¦å­¦ä¹ å’Œ AI è§£å†³æ–¹æ¡ˆã€‚
6. [TensorWatch](https://github.com/microsoft/tensorwatch) - æ·±åº¦å­¦ä¹ çš„è°ƒè¯•å’Œå¯è§†åŒ–å·¥å…·ã€‚
7. [ML Workspace](https://github.com/ml-tooling/ml-workspace) - é¢å‘æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦çš„å…¨åŠŸèƒ½ç½‘é¡µ IDEã€‚
8. [dowel](https://github.com/rlworkgroup/dowel) - ä¸€ä¸ªç”¨äºæœºå™¨å­¦ä¹ ç ”ç©¶çš„å°å‹æ—¥å¿—å·¥å…·ã€‚é€šè¿‡ä¸€æ¬¡è°ƒç”¨ logger.log() å¯ä»¥å°†ä»»ä½•å¯¹è±¡è®°å½•åˆ°æ§åˆ¶å°ã€CSVã€TensorBoardã€æ–‡æœ¬æ—¥å¿—æ–‡ä»¶ç­‰ã€‚
9. [Neptune](https://neptune.ai/) - è½»é‡çº§çš„å®éªŒè·Ÿè¸ªå’Œç»“æœå¯è§†åŒ–å·¥å…·ã€‚
10. [CatalyzeX](https://chrome.google.com/webstore/detail/code-finder-for-research/aikkeehnlfpamidigaffhfmgbkdeheil) - æµè§ˆå™¨æ‰©å±•ï¼ˆChrome å’Œ Firefoxï¼‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ‰¾åˆ°å¹¶é“¾æ¥ ML è®ºæ–‡ä¸­çš„ä»£ç å®ç°ï¼Œé€‚ç”¨äº Googleã€Twitterã€Arxivã€Scholar ç­‰å¹³å°ã€‚
11. [Determined](https://github.com/determined-ai/determined) - æ·±åº¦å­¦ä¹ è®­ç»ƒå¹³å°ï¼Œé›†æˆäº†åˆ†å¸ƒå¼è®­ç»ƒã€è¶…å‚æ•°è°ƒä¼˜ã€æ™ºèƒ½ GPU è°ƒåº¦ã€å®éªŒè·Ÿè¸ªå’Œæ¨¡å‹æ³¨å†Œçš„æ”¯æŒã€‚
12. [DAGsHub](https://dagshub.com/) - å¼€æºæœºå™¨å­¦ä¹ ç¤¾åŒºå¹³å°ï¼Œè½»æ¾ç®¡ç†å®éªŒã€æ•°æ®å’Œæ¨¡å‹ï¼Œå¹¶åˆ›å»ºåä½œå‹æœºå™¨å­¦ä¹ é¡¹ç›®ã€‚  
13. [hub](https://github.com/activeloopai/Hub) - ç”± activeloop.ai æä¾›çš„æœ€å¿«æ— ç»“æ„æ•°æ®é›†ç®¡ç†å·¥å…·ã€‚æµå¼ä¼ è¾“å’Œç‰ˆæœ¬æ§åˆ¶æ•°æ®ï¼Œå°†å¤§å‹æ•°æ®è½¬æ¢ä¸ºäº‘ç«¯å•ä¸€çš„ numpy-like æ•°ç»„ï¼Œä»»ä½•æœºå™¨éƒ½å¯è®¿é—®ã€‚  
14. [DVC](https://dvc.org/) - DVC è¢«è®¾è®¡ç”¨äºè®©æœºå™¨å­¦ä¹ æ¨¡å‹å¯åˆ†äº«å’Œå¯é‡ç°ï¼Œå¤„ç†å¤§æ–‡ä»¶ã€æ•°æ®é›†ã€æœºå™¨å­¦ä¹ æ¨¡å‹ã€åº¦é‡æ ‡å‡†å’Œä»£ç ã€‚ 
15. [CML](https://cml.dev/) - CML å¸®åŠ©ä½ å°†æœ€å–œæ¬¢çš„ DevOps å·¥å…·ä¸æœºå™¨å­¦ä¹ ç»“åˆèµ·æ¥ã€‚
16. [MLEM](https://mlem.ai/) - MLEM æ˜¯ä¸€ä¸ªå·¥å…·ï¼Œå¯ä»¥è½»æ¾æ‰“åŒ…ã€éƒ¨ç½²å’ŒæœåŠ¡æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ”¯æŒå®æ—¶æœåŠ¡å’Œæ‰¹å¤„ç†ç­‰å¤šç§åœºæ™¯ã€‚
17. [Maxim AI](https://getmaxim.ai) - ç”¨äº AI æ™ºèƒ½ä½“æ¨¡æ‹Ÿã€è¯„ä¼°å’Œå¯è§‚å¯Ÿæ€§çš„å·¥å…·ã€‚


## æ¡†æ¶æŒæ¡(tools/æ¡†æ¶.md)
***PyTorch***
**å®‰è£…**
- ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… PyTorchï¼ˆæ ¹æ®ä½ çš„æ“ä½œç³»ç»Ÿé€‰æ‹©å¯¹åº”ç‰ˆæœ¬ï¼‰ï¼š
```bash
pip install torch torchvision torchaudio
```
- ä½ å¯ä»¥è®¿é—® PyTorch å®˜æ–¹ç½‘ç«™é€‰æ‹©é€‚åˆä½ ç³»ç»Ÿçš„ç‰ˆæœ¬ï¼š[PyTorchå®˜ç½‘](https://pytorch.org/get-started/locally/)

***TensorFlow***
**å®‰è£…**
- å®‰è£… TensorFlow çš„æœ€æ–°ç¨³å®šç‰ˆæœ¬ï¼š
```bash
pip install tensorflow
```
- è®¿é—® [TensorFlow](https://www.tensorflow.org/install)å®˜ç½‘è·å–æ›´å¤šå®‰è£…é€‰é¡¹ã€‚

***JAX***
**å®‰è£…**
- ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… JAXï¼ˆå®‰è£… CPU ç‰ˆæœ¬ï¼‰ï¼š
```bash
pip install jax jaxlib
```
- å¯¹äºä½¿ç”¨ GPU çš„ç‰ˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
```bash
pip install jax[cuda]
```
- æ›´å¤šå®‰è£…ä¿¡æ¯è¯·è®¿é—®ï¼š[JAXå®‰è£…é¡µé¢](https://docs.jax.dev/en/latest/installation.html)


## [æ•°æ®å¤„ç†ä¸åˆ†æ](tools/æ•°æ®å¤„ç†ä¸åˆ†æ.md)
***Pandas*** 
- å®‰è£…ï¼š
```bash
pip install pandas
```
- è®¿é—® [Pandaså®˜ç½‘](https://pandas.pydata.org/) è·å–æ›´å¤šä¿¡æ¯ã€‚

***NumPy***
- å®‰è£…ï¼š
```bash
pip install pandas
```
- è®¿é—® [NumPyå®˜ç½‘](https://numpy.org/) äº†è§£æ›´å¤šã€‚

***OpenCV***
- å®‰è£…ï¼š
```bash
pip install opencv-python
```
- è®¿é—® [OpenCVå®˜ç½‘](https://opencv.org/) è·å–æ›´å¤šä¿¡æ¯ã€‚

***NLTK (Natural Language Toolkit)***
- å®‰è£…ï¼š
```bash
pip install nltk
```
- è®¿é—® [NLTKå®˜ç½‘](https://www.nltk.org/) è·å–æ›´å¤šä¿¡æ¯ã€‚


***SciPyï¼š***

- ç”¨é€”ï¼šç”¨äºæ•°å­¦ã€ç§‘å­¦å’Œå·¥ç¨‹è®¡ç®—çš„åº“ï¼Œæä¾›äº†ä¼˜åŒ–ã€çº¿æ€§ä»£æ•°ã€ä¿¡å·å¤„ç†ç­‰åŠŸèƒ½ã€‚

- å®‰è£…ï¼š
```bash
pip install scipy
```

***Matplotlibï¼š***

- ç”¨é€”ï¼šæ•°æ®å¯è§†åŒ–åº“ï¼Œå¹¿æ³›ç”¨äºç”Ÿæˆé™æ€ã€åŠ¨æ€å’Œäº¤äº’å¼å›¾è¡¨ã€‚

- å®‰è£…ï¼š

```bash
pip install matplotlib
```

***Seabornï¼š***

- ç”¨é€”ï¼šåŸºäº Matplotlib çš„æ•°æ®å¯è§†åŒ–åº“ï¼Œæä¾›æ›´é«˜çº§çš„æ¥å£æ¥ç»˜åˆ¶ç»Ÿè®¡å›¾è¡¨ã€‚

- å®‰è£…ï¼š

```bash
pip install seaborn
```

***scikit-learnï¼š***

- ç”¨é€”ï¼šä¸€ä¸ªå¸¸ç”¨çš„æœºå™¨å­¦ä¹ åº“ï¼Œæä¾›äº†åˆ†ç±»ã€å›å½’ã€èšç±»ç­‰å¸¸è§ç®—æ³•ã€‚

- å®‰è£…ï¼š

```bash
pip install scikit-learn
```

***Daskï¼š***

- ç”¨é€”ï¼šå¹¶è¡Œè®¡ç®—æ¡†æ¶ï¼Œèƒ½å¤Ÿæ‰©å±•åˆ°å¤§æ•°æ®é›†ã€‚

- å®‰è£…ï¼š

```bash
pip install dask
```  
## [æ¨¡å‹éƒ¨ç½²](tools/æ¨¡å‹éƒ¨ç½².md)
***ONNX (Open Neural Network Exchange)***

- å®‰è£…ï¼š

```bash
pip install onnx
```
- è®¿é—® [ONNXå®˜ç½‘](https://onnx.ai/) è·å–æ›´å¤šä¿¡æ¯ã€‚

***TensorRT***

- å®‰è£…ï¼š

- TensorRT é€šå¸¸éœ€è¦é€šè¿‡ NVIDIA çš„å®˜æ–¹ç½‘ç«™è¿›è¡Œä¸‹è½½ã€‚è®¿é—® [NVIDIA TensorRT](https://developer.nvidia.com/tensorrt) ä»¥è·å–å®‰è£…ä¿¡æ¯ã€‚

***Flaskå®‰è£…ï¼š***
```bash
pip install flask
```
***Djangoå®‰è£…ï¼š***
```bash
pip install django
```
- è®¿é—® [Flaskå®˜ç½‘](https://flask.palletsprojects.com/en/2.0.x/) å’Œ [Djangoå®˜ç½‘](https://www.djangoproject.com/) è·å–æ›´å¤šä¿¡æ¯ã€‚

***TensorFlow Servingï¼š***

- ç”¨é€”ï¼šä¸º TensorFlow æ¨¡å‹æä¾›é«˜æ•ˆçš„åœ¨çº¿æœåŠ¡ã€‚

- å®‰è£…ï¼š

```bash
docker pull tensorflow/serving
```

***FastAPIï¼š***

- ç”¨é€”ï¼šç°ä»£çš„ Web æ¡†æ¶ï¼Œç”¨äºæ„å»º APIsï¼Œé€‚åˆä¸æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸€èµ·éƒ¨ç½²ã€‚

- å®‰è£…ï¼š

```bash
pip install fastapi
```

***Streamlitï¼š***

- ç”¨é€”ï¼šç”¨äºå¿«é€Ÿåˆ›å»ºå’Œå…±äº«æœºå™¨å­¦ä¹ åº”ç”¨çš„å·¥å…·ã€‚

- å®‰è£…ï¼š

```bash
pip install streamlit
```

## [MLOpsåŸºç¡€å’Œç›‘æ§](tools/MLOpsåŸºç¡€å’Œç›‘æ§.md)
***MLflow***

**å®‰è£…ï¼š**

```bash
pip install mlflow
```
- è®¿é—® [MLflowå®˜ç½‘](https://mlflow.org/) è·å–æ›´å¤šä¿¡æ¯ã€‚

***Weights & Biases***

**å®‰è£…ï¼š**

```bash
pip install wandb
```
- è®¿é—® [Weights & Biaseså®˜ç½‘](https://wandb.ai/site) è·å–æ›´å¤šä¿¡æ¯ã€‚

***Docker***

**å®‰è£…ï¼š**

- è®¿é—® [Dockerå®˜ç½‘](https://www.docker.com/products/docker-desktop) ä¸‹è½½ Docker Desktopï¼Œé€‚ç”¨äº Windows å’Œ macOSã€‚

- å¯¹äº Linux ç”¨æˆ·ï¼Œå¯ä»¥æ ¹æ®ä½ çš„å‘è¡Œç‰ˆä½¿ç”¨åŒ…ç®¡ç†å™¨è¿›è¡Œå®‰è£…ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Ubuntuï¼š
```bash
sudo apt install docker.io
```
- è®¿é—® [Dockerå®‰è£…é¡µé¢](https://docs.docker.com/get-docker/) è·å–æ›´å¤šä¿¡æ¯ã€‚

***Kubeflowï¼š***

- ç”¨é€”ï¼šä¸º Kubernetes æä¾›ç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ å·¥ä½œæµå·¥å…·ã€‚

**å®‰è£…ï¼š**

```bash
pip install kubeflow
```

***TensorBoardï¼š***

- ç”¨é€”ï¼šTensorFlow çš„å¯è§†åŒ–å·¥å…·ï¼Œç”¨äºæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡ã€‚

**å®‰è£…ï¼š**

```bash
pip install tensorboard
```

***Prometheusï¼š***

- ç”¨é€”ï¼šå¼€æºç›‘æ§ç³»ç»Ÿï¼Œèƒ½å¤Ÿç›‘æ§æœºå™¨å­¦ä¹ å·¥ä½œæµå’Œéƒ¨ç½²ã€‚

**å®‰è£…ï¼š**

```bash
docker pull prom/prometheus
```

## [å¼ºåŒ–å­¦ä¹ ](tools/å¼ºåŒ–å­¦ä¹ .md)
***OpenAI Gymï¼š***

- ç”¨é€”ï¼šå¼ºåŒ–å­¦ä¹ çš„å·¥å…·åŒ…ï¼Œæä¾›å„ç§æ¨¡æ‹Ÿç¯å¢ƒã€‚

- å®‰è£…ï¼š

```bash
pip install gym
```

***Stable Baselines3ï¼š***

- ç”¨é€”ï¼šå¼ºåŒ–å­¦ä¹ çš„é«˜æ•ˆå®ç°ï¼ŒåŸºäº PyTorchã€‚

- å®‰è£…ï¼š

```bash
pip install stable-baselines3
```

***Ray RLlibï¼š***

- ç”¨é€”ï¼šä¸€ä¸ªç”¨äºå¼ºåŒ–å­¦ä¹ çš„åˆ†å¸ƒå¼è®¡ç®—åº“ï¼Œèƒ½å¤Ÿæ‰©å±•åˆ°å¤§è§„æ¨¡åˆ†å¸ƒå¼ç¯å¢ƒã€‚

- å®‰è£…ï¼š
```bash
pip install ray[rllib]
```

## [æ¨¡å‹ä¼˜åŒ–ä¸åŠ é€Ÿå·¥å…·](tools/æ¨¡å‹ä¼˜åŒ–ä¸åŠ é€Ÿå·¥å…·.md)
***TensorFlow Liteï¼š***

- ç”¨é€”ï¼šç”¨äºåœ¨ç§»åŠ¨è®¾å¤‡æˆ–è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è½»é‡çº§ç‰ˆæœ¬ã€‚

- å®‰è£…ï¼š

```bash
pip install tflite
```

***NVIDIA Apexï¼š***

- ç”¨é€”ï¼šNVIDIA æä¾›çš„åº“ï¼Œä¼˜åŒ– PyTorch ä¸­çš„æ··åˆç²¾åº¦è®­ç»ƒã€‚

- å®‰è£…ï¼š

```bash
pip install apex
```

***Horovodï¼š***

- ç”¨é€”ï¼šåˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ åº“ï¼Œç”¨äºåŠ é€Ÿ TensorFlowã€Keras å’Œ PyTorch çš„è®­ç»ƒã€‚

- å®‰è£…ï¼š

```bash
pip install horovod
```

## [æ·±åº¦å­¦ä¹ å·¥å…·](tools/æ·±åº¦å­¦ä¹ å·¥å…·.md)
***Keras:***
- ç”¨é€”ï¼šé«˜å±‚ç¥ç»ç½‘ç»œ APIï¼Œæ”¯æŒ TensorFlowã€Theano ç­‰åç«¯ã€‚

- å®‰è£…ï¼š

```bash
pip install keras
```

***Fastaiï¼š***

- ç”¨é€”ï¼šä¸€ä¸ªæ„å»ºåœ¨ PyTorch ä¹‹ä¸Šçš„æ·±åº¦å­¦ä¹ åº“ï¼Œæä¾›æ˜“ç”¨çš„ API è¿›è¡Œè®­ç»ƒã€‚

- å®‰è£…ï¼š

```bash
pip install fastai
```

***Hugging Face Transformersï¼š***

- ç”¨é€”ï¼šç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„é¢„è®­ç»ƒæ¨¡å‹åº“ï¼Œæ”¯æŒ Transformer æ¨¡å‹ï¼ˆå¦‚ BERTã€GPTï¼‰ã€‚

- å®‰è£…ï¼š

```bash
pip install transformers
```

***MXNetï¼š***

- ç”¨é€”ï¼šApache ç»´æŠ¤çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

- å®‰è£…ï¼š

```bash
pip install mxnet
```

***Chainerï¼š***

- ç”¨é€”ï¼šä¸€ç§çµæ´»çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€‚åˆå¿«é€ŸåŸå‹è®¾è®¡å’Œå®éªŒã€‚

- å®‰è£…ï¼š

```bash
pip install chainer
```

## [è‡ªåŠ¨åŒ–å’Œå·¥å…·é›†æˆ.](tools/è‡ªåŠ¨åŒ–å’Œå·¥å…·é›†æˆ.md)
***Apache Airflowï¼š***

- ç”¨é€”ï¼šå·¥ä½œæµè°ƒåº¦å’Œç®¡ç†å·¥å…·ï¼Œç”¨äºè‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚

**å®‰è£…ï¼š**

```bash
pip install apache-airflow
```

***Celeryï¼š***

- ç”¨é€”ï¼šåˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—ï¼Œå¯ä»¥å¸®åŠ©ä½ ç®¡ç†å’Œè°ƒåº¦åå°ä»»åŠ¡ã€‚

**å®‰è£…ï¼š**

```bash
pip install celery
```

***Luigiï¼š***

- ç”¨é€”ï¼šPython ä»»åŠ¡æ¡†æ¶ï¼Œé€‚ç”¨äºæ‰¹å¤„ç†æ•°æ®ä»»åŠ¡çš„è°ƒåº¦ã€‚

**å®‰è£…ï¼š**

```bash
pip install luigi
```

## [è®¡ç®—æœºè§†è§‰](tools/è®¡ç®—æœºè§†è§‰.md)
***PyTorch Lightningï¼š***

- ç”¨é€”ï¼šç®€åŒ– PyTorch ä»£ç çš„æ¡†æ¶ï¼Œå‡å°‘æ ·æ¿ä»£ç ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§ã€‚

- å®‰è£…ï¼š

```bash
pip install pytorch-lightning
```

***Albumentationsï¼š***

- ç”¨é€”ï¼šè®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒå¢å¼ºåº“ï¼Œæ”¯æŒå¤šç§å¸¸ç”¨å›¾åƒå¤„ç†æ“ä½œã€‚

- å®‰è£…ï¼š

```bash
pip install albumentations
```

***Detectron2ï¼š***

- ç”¨é€”ï¼šç”± Facebook AI ç ”ç©¶é™¢ï¼ˆFAIRï¼‰å¼€å‘çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼ŒåŸºäº PyTorchã€‚

- å®‰è£…ï¼š

```bash
pip install detectron2
```

---

# ğŸš§ å®æˆ˜é¡¹ç›®ç¤ºä¾‹
## CNNå›¾åƒåˆ†ç±»ç¤ºä¾‹ - PyTorch

```python
# CNNå›¾åƒåˆ†ç±»ç¤ºä¾‹ - PyTorch
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, datasets
```

### 1. åŠ è½½æ•°æ®é›†
```python
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)
```

### 2. æ„å»ºCNNæ¨¡å‹
```python
class CNNClassifier(nn.Module):
    def __init__(self):
        super(CNNClassifier, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(64 * 8 * 8, 512)
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        x = self.flatten(x)
        x = self.relu3(self.fc1(x))
        x = self.fc2(x)
        return x

model = CNNClassifier()
```

### 3. è®­ç»ƒæ¨¡å‹
```python
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(10):
    running_loss = 0.0
    for i, (images, labels) in enumerate(train_loader, 0):
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        
    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')

print('è®­ç»ƒå®Œæˆ!')
```

## [ğŸ” æ›´å¤šå®Œæ•´é¡¹ç›®ï¼š](Project)

- [NLP â€” NLP å®æˆ˜é¡¹ç›®é›†](https://github.com/0voice/learning-Journey-AI/tree/main/Project/NLP)
- [Phase0 â€” åŸºç¡€ç¼–ç¨‹ç»ƒä¹ åˆé›†](https://github.com/0voice/learning-Journey-AI/tree/main/Project/Phase0)
- [Phase1 â€” æœºå™¨å­¦ä¹ åŸºç¡€é¡¹ç›®é›†](https://github.com/0voice/learning-Journey-AI/tree/main/Project/Phase1)
- [Phase2 â€” æ·±åº¦å­¦ä¹ å®æˆ˜é¡¹ç›®é›†ï¼ˆPyTorchï¼‰](https://github.com/0voice/learning-Journey-AI/tree/main/Project/Phase2)
- [Phase3ï¼šAI è®¡ç®—æœºè§†è§‰å®æˆ˜é¡¹ç›®åˆé›†](https://github.com/0voice/learning-Journey-AI/tree/main/Project/Phase3)
- [ai-chatbot](https://github.com/0voice/learning-Journey-AI/tree/main/Project/ai-chatbot)
- [ai-code-assistant](https://github.com/0voice/learning-Journey-AI/tree/main/Project/ai-code-assistant)
- [ai-image-search](https://github.com/0voice/learning-Journey-AI/tree/main/Project/ai-image-search)
- [ai-interviewer](https://github.com/0voice/learning-Journey-AI/tree/main/Project/ai-interviewer)
- [ai-math-grader](https://github.com/0voice/learning-Journey-AI/tree/main/Project/ai-math-grader)
- [universal-recommender](https://github.com/0voice/learning-Journey-AI/tree/main/Project/universal-recommender)
- [å›¾åƒåˆ†ç±»å®æˆ˜](https://github.com/0voice/learning-Journey-AI/blob/main/Project/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%AE%9E%E6%88%98.md)
- [æ–‡æœ¬æƒ…æ„Ÿåˆ†æ](https://github.com/0voice/learning-Journey-AI/blob/main/Project/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90.md)
- [èŠå¤©æœºå™¨äººæ„å»º](https://github.com/0voice/learning-Journey-AI/blob/main/Project/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%9E%84%E5%BB%BA.md)


### ğŸ”— å®ç”¨èµ„æºè¡¥å……
| ç±»å‹      | æ¨èé“¾æ¥                                                           |
| ------- | -------------------------------------------------------------- |
| é¡¹ç›®ä»£ç é›†   | [PyTorch Examples](https://github.com/pytorch/examples)        |
| AIè¯¾ç¨‹é¡¹ç›®åº“ | [Full Stack Deep Learning](https://fullstackdeeplearning.com/) |
| AIæ¯”èµ›    | [Kaggle Competitions](https://www.kaggle.com/competitions)     |
| NLPé¡¹ç›®åˆé›† | [Awesome NLP Projects](https://github.com/keon/awesome-nlp)    |

---

# ğŸ“š æ ¸å¿ƒèµ„æºæ€»è§ˆ
## [ğŸ¥åœ¨çº¿è¯¾ç¨‹æ¨è](Course)

1. [æ·±åº¦å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹ï¼ˆDeep Learning Specializationï¼‰](https://www.coursera.org/specializations/deep-learning) - å´æ©è¾¾æ•™æˆä¸»è®²ï¼Œå†…å®¹æ¶µç›–ç¥ç»ç½‘ç»œã€CNNã€RNN ç­‰ã€‚

2. [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹](https://courses.d2l.ai/zh-v2/) - åŸºäº PyTorch å’Œ MXNet çš„æ·±åº¦å­¦ä¹ å®è·µè¯¾ç¨‹ã€‚

3. [æå®æ¯…æ·±åº¦å­¦ä¹ æ•™ç¨‹](https://github.com/datawhalechina/leedl-tutorial) - æå®æ¯…æ•™æˆçš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œå†…å®¹æ·±å…¥æµ…å‡ºã€‚

4. [Google æœºå™¨å­¦ä¹ é€Ÿæˆè¯¾ç¨‹](https://developers.google.com/machine-learning/crash-course?hl=zh-cn) - é€‚åˆæœºå™¨å­¦ä¹ åˆå­¦è€…çš„å…¥é—¨è¯¾ç¨‹ã€‚

5. [NVIDIA æ·±åº¦å­¦ä¹ åŸ¹è®­ä¸­å¿ƒï¼ˆDLIï¼‰](https://zh.wikipedia.org/wiki/NVIDIA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%B9%E8%AE%AD%E4%B8%AD%E5%BF%83) - æä¾›æ·±åº¦å­¦ä¹ ã€åŠ é€Ÿè®¡ç®—ã€æ•°æ®ç§‘å­¦ç­‰é¢†åŸŸçš„å¼€å‘åŸ¹è®­ã€‚

6. [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) - æ–¯å¦ç¦å¤§å­¦çš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œä¸“æ³¨äºè®¡ç®—æœºè§†è§‰å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€‚

7. [æœºå™¨å­¦ä¹ åŸºç¡€ï¼ˆMachine Learning by Stanford Universityï¼‰](https://www.coursera.org/learn/machine-learning?utm_source=chatgpt.com) - ç”± Andrew Ng ä¸»è®²çš„ç»å…¸æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œæ¶µç›–ç›‘ç£å­¦ä¹ ã€éç›‘ç£å­¦ä¹ å’Œå…¶ä»–åŸºæœ¬æ¦‚å¿µã€‚

8. [Fast.ai æ·±åº¦å­¦ä¹ è¯¾ç¨‹](https://course.fast.ai/) - åŸºäº PyTorch çš„æ·±åº¦å­¦ä¹ å¿«é€Ÿå…¥é—¨è¯¾ç¨‹ï¼Œæ—¨åœ¨è®©æ¯ä¸ªäººéƒ½èƒ½å¿«é€Ÿå®è·µæ·±åº¦å­¦ä¹ ã€‚

9. [Deep Learning for Computer Vision (Udacity)](https://www.udacity.com/course/deep-learning-pytorch--ud188) - Udacity æä¾›çš„æ·±åº¦å­¦ä¹ è®¡ç®—æœºè§†è§‰è¯¾ç¨‹ï¼Œæ•™æˆå¦‚ä½•ä½¿ç”¨ PyTorch å®ç°å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰ä»»åŠ¡ã€‚

10. [Deep Learning Nanodegree (Udacity)](https://www.udacity.com/course/deep-learning-nanodegree--nd101) - Udacity çš„æ·±åº¦å­¦ä¹ çº³ç±³å­¦ä½è¯¾ç¨‹ï¼Œè¦†ç›–ç¥ç»ç½‘ç»œã€å·ç§¯ç¥ç»ç½‘ç»œã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç­‰å†…å®¹ã€‚

11. [CS224n: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/) - æ–¯å¦ç¦å¤§å­¦çš„æ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†è¯¾ç¨‹ï¼Œé‡ç‚¹è®²è§£å¦‚ä½•åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯è¿›è¡Œæ–‡æœ¬å¤„ç†å’Œåˆ†æã€‚

12. [Deep Learning with TensorFlow](https://www.edx.org/course/deep-learning-with-tensorflow) - edX ä¸Šçš„ TensorFlow æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œé€‚åˆæƒ³è¦å­¦ä¹ ä½¿ç”¨ TensorFlow è¿›è¡Œæ·±åº¦å­¦ä¹ çš„å¼€å‘è€…ã€‚

13. [Practical Deep Learning for Coders](https://course.fast.ai/) - Fast.ai æä¾›çš„åœ¨çº¿è¯¾ç¨‹ï¼Œé¢å‘å¼€å‘è€…ï¼Œé€šè¿‡å®è·µè®²è§£æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µå’Œåº”ç”¨ã€‚

14. [MIT 6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/) - éº»çœç†å·¥å­¦é™¢çš„æ·±åº¦å­¦ä¹ å…¥é—¨è¯¾ç¨‹ï¼Œæ¶µç›–åŸºæœ¬çš„æ·±åº¦å­¦ä¹ æ¦‚å¿µã€å·ç§¯ç¥ç»ç½‘ç»œã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç­‰ã€‚

15. [Data Science and Machine Learning Bootcamp with R](https://www.udemy.com/course/data-science-and-machine-learning-bootcamp-with-r/) - Udemy ä¸Šçš„ R è¯­è¨€æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œé€‚åˆæƒ³ç”¨ R è¿›è¡Œæœºå™¨å­¦ä¹ çš„å¼€å‘è€…ã€‚

16. [AI for Everyone (Coursera)](https://www.coursera.org/learn/ai-for-everyone) - å´æ©è¾¾æ•™æˆçš„äººå·¥æ™ºèƒ½å…¥é—¨è¯¾ç¨‹ï¼Œæ—¨åœ¨ä¸ºæ²¡æœ‰æŠ€æœ¯èƒŒæ™¯çš„äººæä¾› AI åŸºç¡€çŸ¥è¯†ã€‚

17. [Deep Learning with PyTorch](https://pytorch.org/tutorials/) - PyTorch å®˜æ–¹æä¾›çš„æ·±åº¦å­¦ä¹ æ•™ç¨‹ï¼Œæ¶µç›–ä»åŸºç¡€åˆ°é«˜çº§çš„æ·±åº¦å­¦ä¹ çŸ¥è¯†ï¼Œé€‚åˆä¸åŒæ°´å¹³çš„å­¦ä¹ è€…ã€‚

18. [Reinforcement Learning Specialization](https://www.coursera.org/specializations/reinforcement-learning) - Coursera ä¸Šçš„å¼ºåŒ–å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹ï¼Œæ•™æˆå¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µå’Œå®é™…åº”ç”¨ã€‚

19. [Stanford CS20: TensorFlow for Deep Learning Research](https://web.stanford.edu/class/cs20si/) - æ–¯å¦ç¦å¤§å­¦çš„è¯¾ç¨‹ï¼Œæ·±å…¥è®²è§£ TensorFlow åŠå…¶åœ¨æ·±åº¦å­¦ä¹ ç ”ç©¶ä¸­çš„åº”ç”¨ã€‚

20. [Applied Data Science with Python (University of Michigan)](https://www.coursera.org/specializations/data-science-python) - å¯†æ­‡æ ¹å¤§å­¦çš„ Python æ•°æ®ç§‘å­¦åº”ç”¨è¯¾ç¨‹ï¼Œæ¶µç›–æœºå™¨å­¦ä¹ ã€æ•°æ®å¤„ç†ã€æ•°æ®å¯è§†åŒ–ç­‰å†…å®¹ã€‚

21. [Introduction to Machine Learning with Python](https://www.udemy.com/course/machine-learning-with-python/) - Udemy æä¾›çš„ Python æœºå™¨å­¦ä¹ å…¥é—¨è¯¾ç¨‹ï¼Œé€‚åˆåˆšæ¥è§¦æœºå™¨å­¦ä¹ çš„åˆå­¦è€…ã€‚

22. [Practical Reinforcement Learning](https://www.udemy.com/course/practical-reinforcement-learning/) - Udemy ä¸Šçš„å¼ºåŒ–å­¦ä¹ å®è·µè¯¾ç¨‹ï¼Œæ¶µç›– Q-learningã€æ·±åº¦ Q ç½‘ç»œç­‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚

23. [Mastering Machine Learning with scikit-learn](https://www.udemy.com/course/master-machine-learning-with-scikit-learn/) - Udemy ä¸Šçš„ scikit-learn æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œé€‚åˆ Python ç”¨æˆ·ä½¿ç”¨ scikit-learn åº“è¿›è¡Œæœºå™¨å­¦ä¹ ã€‚

24. [Introduction to Artificial Intelligence (AI)](https://www.edx.org/course/artificial-intelligence-ai) - edX æä¾›çš„äººå·¥æ™ºèƒ½å…¥é—¨è¯¾ç¨‹ï¼Œé€‚åˆ AI åˆå­¦è€…ï¼Œè¦†ç›–åŸºç¡€æ¦‚å¿µã€åº”ç”¨å’Œæ–¹æ³•ã€‚

25. [AI for Robotics (Udacity)](https://www.udacity.com/course/ai-for-robotics--ud980) - Udacity ä¸Šçš„äººå·¥æ™ºèƒ½ä¸æœºå™¨äººè¯¾ç¨‹ï¼Œæ¶µç›–è·¯å¾„è§„åˆ’ã€è§†è§‰å¤„ç†ç­‰ AI åœ¨æœºå™¨äººé¢†åŸŸçš„åº”ç”¨ã€‚

26. [AI Programming with Python (Udacity)](https://www.udacity.com/course/ai-programming-with-python-nanodegree--nd089) - Udacity æä¾›çš„ AI ç¼–ç¨‹è¯¾ç¨‹ï¼Œé€‚åˆåˆå­¦è€…ï¼Œæ¶µç›– Python ç¼–ç¨‹ã€NumPyã€Pandasã€Matplotlibã€PyTorch å’Œæ·±åº¦å­¦ä¹ åŸºç¡€ã€‚

27. [Neural Networks and Deep Learning (Coursera)](https://www.coursera.org/learn/neural-networks-deep-learning) - ç”± Andrew Ng ä¸»è®²çš„ç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œé€‚åˆæ·±åº¦å­¦ä¹ åˆå­¦è€…ã€‚

28. [Intro to TensorFlow for Deep Learning (Udacity)](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187) - ç”± Udacity æä¾›çš„ TensorFlow æ·±åº¦å­¦ä¹ å…¥é—¨è¯¾ç¨‹ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨ TensorFlow æ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

29. [Reinforcement Learning (Udacity)](https://www.udacity.com/course/reinforcement-learning--ud600) - Udacity æä¾›çš„å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ï¼Œé€‚åˆå¸Œæœ›æ·±å…¥ç†è§£å¼ºåŒ–å­¦ä¹ åŠå…¶åº”ç”¨çš„å¼€å‘è€…ã€‚

30. [Applied AI with DeepLearning (Coursera)](https://www.coursera.org/specializations/applied-ai) - æ·±å…¥å­¦ä¹ å¦‚ä½•å°† AI å’Œæ·±åº¦å­¦ä¹ åº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­ï¼ŒåŒ…æ‹¬è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚

31. [Practical Deep Learning for Coders v4 (Fast.ai)](https://course.fast.ai/) - Fast.ai æä¾›çš„æ·±åº¦å­¦ä¹ å®è·µè¯¾ç¨‹ï¼Œé€‚åˆå¸Œæœ›åœ¨ PyTorch ä¸Šå¿«é€Ÿæ„å»ºæ·±åº¦å­¦ä¹ é¡¹ç›®çš„å¼€å‘è€…ã€‚

32. [Deep Reinforcement Learning (Coursera)](https://www.coursera.org/specializations/deep-reinforcement-learning) - è¯¾ç¨‹ä¸“æ³¨äºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åº”ç”¨ï¼Œè¦†ç›–ç®—æ³•ã€ç¯å¢ƒå’Œæ¨¡å‹è®­ç»ƒç­‰å†…å®¹ã€‚

33. [Introduction to Deep Learning with Keras (DataCamp)](https://www.datacamp.com/courses/deep-learning-with-keras) - DataCamp æä¾›çš„ Keras æ·±åº¦å­¦ä¹ å…¥é—¨è¯¾ç¨‹ï¼Œå¸®åŠ©å­¦ç”Ÿç†è§£ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ çš„åŸºç¡€æ¦‚å¿µã€‚

34. [Neural Networks and Deep Learning (Stanford)](http://cs231n.stanford.edu/) - æ–¯å¦ç¦å¤§å­¦æ·±åº¦å­¦ä¹ è¯¾ç¨‹ï¼Œä¸“æ³¨äºè®¡ç®—æœºè§†è§‰å’Œæ·±åº¦ç¥ç»ç½‘ç»œçš„åº”ç”¨ã€‚

35. [Machine Learning with TensorFlow on Google Cloud (Coursera)](https://www.coursera.org/professional-certificates/machine-learning-tensorflow-gcp) - ç”± Google æä¾›çš„ TensorFlow å’Œæœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œå­¦ä¹ å¦‚ä½•åœ¨ Google Cloud ä¸Šéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

36. [Building Conversational Experiences with Dialogflow (Coursera)](https://www.coursera.org/learn/building-conversational-experiences-dialogflow) - Google æä¾›çš„è¯¾ç¨‹ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨ Dialogflow æ„å»ºèŠå¤©æœºå™¨äººã€‚

37. [Advanced Machine Learning Specialization (Coursera)](https://www.coursera.org/specializations/advanced-machine-learning) - é€‚åˆå…·æœ‰æœºå™¨å­¦ä¹ åŸºç¡€çš„å­¦ç”Ÿï¼Œè¯¾ç¨‹æ¶‰åŠæ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é«˜çº§ä¸»é¢˜ã€‚

38. [Data Science and Machine Learning Bootcamp with R (Udemy)](https://www.udemy.com/course/data-science-and-machine-learning-bootcamp-with-r/) - ä½¿ç”¨ R è¯­è¨€è¿›è¡Œæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„å…¥é—¨è¯¾ç¨‹ï¼Œé€‚åˆåˆå­¦è€…ã€‚

39. [Introduction to Machine Learning with Python (Udemy)](https://www.udemy.com/course/machine-learning-with-python/) - é€šè¿‡ Python å­¦ä¹ æœºå™¨å­¦ä¹ çš„åŸºç¡€ï¼ŒåŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€éç›‘ç£å­¦ä¹ å’Œæ¨¡å‹è¯„ä¼°ç­‰ã€‚

40. [Deep Learning for Business with TensorFlow (Udemy)](https://www.udemy.com/course/deep-learning-for-business-with-tensorflow/) - æ·±åº¦å­¦ä¹ å•†ä¸šåº”ç”¨è¯¾ç¨‹ï¼Œä¸“æ³¨äºåˆ©ç”¨ TensorFlow æ„å»ºå•†ä¸šæ™ºèƒ½å’Œé¢„æµ‹æ¨¡å‹ã€‚

41. [Natural Language Processing with Deep Learning in Python (Udemy)](https://www.udemy.com/course/natural-language-processing-with-deep-learning-in-python/) - é€šè¿‡ Python å­¦ä¹ ä½¿ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ã€‚

42. [Computer Vision with Python (Udemy)](https://www.udemy.com/course/computer-vision-with-python/) - ä½¿ç”¨ Python å’Œ OpenCV å­¦ä¹ è®¡ç®—æœºè§†è§‰æŠ€æœ¯ï¼Œæ¶µç›–å›¾åƒå¤„ç†ã€å¯¹è±¡æ£€æµ‹ç­‰å†…å®¹ã€‚

43. [Generative Adversarial Networks (GANs) Specialization (Coursera)](https://www.coursera.org/specializations/generative-adversarial-networks) - Coursera ä¸Šçš„ GANs ä¸“é¡¹è¯¾ç¨‹ï¼Œæ·±å…¥å­¦ä¹ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œå…¶åº”ç”¨ã€‚

44. [TensorFlow for Deep Learning (Udacity)](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187) - é€šè¿‡ TensorFlow å­¦ä¹ æ·±åº¦å­¦ä¹ æ¨¡å‹çš„åˆ›å»ºå’Œè®­ç»ƒï¼Œé€‚åˆæœ‰ç¼–ç¨‹åŸºç¡€çš„å­¦ä¹ è€…ã€‚

45. [AI Programming with Python Nanodegree (Udacity)](https://www.udacity.com/course/ai-programming-with-python-nanodegree--nd089) - Udacity çš„ AI ç¼–ç¨‹è¯¾ç¨‹ï¼Œæ¶µç›– Python ç¼–ç¨‹ã€æ•°æ®ç»“æ„ã€ç®—æ³•å’Œæ·±åº¦å­¦ä¹ ã€‚

46. [Machine Learning with Python (Coursera)](https://www.coursera.org/learn/machine-learning-with-python) - ç”± IBM æä¾›çš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œä½¿ç”¨ Python è®²è§£æœºå™¨å­¦ä¹ ç®—æ³•å’Œå®è·µã€‚

47. [Deep Learning with PyTorch (Udacity)](https://www.udacity.com/course/deep-learning-pytorch--ud188) - ä½¿ç”¨ PyTorch è¿›è¡Œæ·±åº¦å­¦ä¹ çš„è¯¾ç¨‹ï¼Œé€‚åˆå­¦ä¹ è€…æƒ³è¦æ·±å…¥ç†è§£ç¥ç»ç½‘ç»œå’Œæ¨¡å‹è®­ç»ƒã€‚

48. [Artificial Intelligence: A Modern Approach (Stanford)](https://www.ai-class.com/) - æ–¯å¦ç¦å¤§å­¦çš„ç»å…¸äººå·¥æ™ºèƒ½è¯¾ç¨‹ï¼Œæ¶‰åŠæœç´¢ç®—æ³•ã€å­¦ä¹ ç®—æ³•ã€é€»è¾‘æ¨ç†ç­‰é¢†åŸŸã€‚

49. [ML and AI for Business (Udemy)](https://www.udemy.com/course/machine-learning-and-artificial-intelligence-for-business/) - é€‚åˆå•†ä¸šä¸“ä¸šäººå£«çš„ AI å’Œæœºå™¨å­¦ä¹ è¯¾ç¨‹ï¼Œå­¦ä¹ å¦‚ä½•å°†è¿™äº›æŠ€æœ¯åº”ç”¨äºå®é™…ä¸šåŠ¡åœºæ™¯ä¸­ã€‚

50. [Mastering Machine Learning with Python (Udemy)](https://www.udemy.com/course/master-machine-learning-with-python/) - é€šè¿‡ Python å­¦ä¹ å¦‚ä½•æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„å…¨è¿‡ç¨‹ã€‚

51. [AI with Python (Udemy)](https://www.udemy.com/course/artificial-intelligence-with-python/) - ä»‹ç»å¦‚ä½•ä½¿ç”¨ Python å®ç°äººå·¥æ™ºèƒ½åº”ç”¨ï¼Œé€‚åˆ AI åˆå­¦è€…ã€‚

52. [Introduction to Artificial Intelligence with Python (Harvard)](https://www.edx.org/course/cs50s-introduction-to-artificial-intelligence-with-python) - å“ˆä½›å¤§å­¦çš„ AI å…¥é—¨è¯¾ç¨‹ï¼Œä½¿ç”¨ Python è®²è§£äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼ŒåŒ…æ‹¬æœç´¢ç®—æ³•ã€ç¥ç»ç½‘ç»œç­‰ã€‚

53. [Applied Machine Learning (Coursera)](https://www.coursera.org/specializations/applied-machine-learning) - ä¸“æ³¨äºæœºå™¨å­¦ä¹ ç®—æ³•çš„å®é™…åº”ç”¨ï¼Œæ¶µç›–å›å½’ã€åˆ†ç±»ã€èšç±»ã€ç‰¹å¾é€‰æ‹©ç­‰ã€‚

54. [Advanced Deep Learning & Reinforcement Learning (Udacity)](https://www.udacity.com/course/advanced-deep-learning-and-reinforcement-learning-nanodegree--nd893) - Udacity æä¾›çš„æ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ é«˜çº§è¯¾ç¨‹ï¼Œé€‚åˆæœ‰åŸºç¡€çš„å­¦ä¹ è€…ï¼Œæ·±å…¥ç†è§£å¤æ‚æ¨¡å‹å’Œç®—æ³•ã€‚

## [ğŸ“–ç”µå­ä¹¦ç±ç²¾é€‰](books)

1. [ã€Šæ·±åº¦å­¦ä¹ ã€‹ - Ian Goodfellow, Yoshua Bengio, Aaron Courville](https://www.deeplearningbook.org/)  
   æ·±åº¦å­¦ä¹ é¢†åŸŸçš„ç»å…¸æ•™æï¼Œæ¶µç›–äº†æ·±åº¦å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ã€å·ç§¯ç¥ç»ç½‘ç»œã€é€’å½’ç¥ç»ç½‘ç»œç­‰å†…å®¹ã€‚

2. [ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹ - Andrew Ng](https://www.deeplearning.ai/machine-learning-yearning/)  
   å´æ©è¾¾æ•™æˆç¼–å†™çš„æœºå™¨å­¦ä¹ å®è·µæŒ‡å—ï¼Œé‡ç‚¹è®²è§£å¦‚ä½•æ­å»ºã€è°ƒä¼˜å’Œä¼˜åŒ–æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚

3. [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹ - èµµå¿—çº¢, ææ²](https://zh.d2l.ai/)  
   åŸºäº Python å’Œ MXNet çš„æ·±åº¦å­¦ä¹ å®è·µä¹¦ç±ï¼Œé€‚åˆä»é›¶å¼€å§‹çš„å­¦ä¹ è€…ã€‚

4. [ã€ŠPythonæœºå™¨å­¦ä¹ ã€‹ - Sebastian Raschka](https://sebastianraschka.com/books.html)  
   ä»‹ç»å¦‚ä½•ä½¿ç”¨ Python åŠå…¶ç›¸å…³åº“ï¼ˆå¦‚ scikit-learnï¼‰æ¥å®ç°æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œé€‚åˆåˆå­¦è€…å’Œä¸­çº§å¼€å‘è€…ã€‚

5. [ã€ŠPython æ·±åº¦å­¦ä¹ ã€‹ - FranÃ§ois Chollet](https://www.packtpub.com/product/python-deep-learning-second-edition/9781838983011)  
   Keras çš„åˆ›é€ è€… FranÃ§ois Chollet ç¼–å†™çš„æ·±åº¦å­¦ä¹ ä¹¦ç±ï¼Œç»“åˆäº†ç†è®ºä¸å®è·µï¼Œé€‚åˆå¼€å‘è€…å’Œæ•°æ®ç§‘å­¦å®¶ã€‚

6. [ã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ï¼šåŸºäºPythonçš„ç†è®ºä¸å®ç°ã€‹ - æ–‹è—¤åº·æ¯…](https://www.oreilly.com/library/view/deep-learning-from/9781492041412/)  
   æœ¬ä¹¦ä»¥ TensorFlow å’Œ Keras ä¸ºå·¥å…·ï¼Œè®²è§£æ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŸç†å’Œå®ç°æ–¹æ³•ã€‚

7. [ã€Šæœºå™¨å­¦ä¹ ï¼šæ¦‚ç‡è§†è§’ã€‹ - Kevin P. Murphy](http://www.cs.ubc.ca/~murphyk/MLbook/)  
   æ·±å…¥æ¢è®¨æœºå™¨å­¦ä¹ ä¸­çš„æ¦‚ç‡æ¨¡å‹å’Œæ¨ç†æ–¹æ³•ã€‚

8. [ã€Šå¼ºåŒ–å­¦ä¹ ï¼šAn Introductionã€‹ - Richard S. Sutton & Andrew G. Barto](http://incompleteideas.net/book/the-book-2nd.html)  
   æ·±å…¥è®²è§£å¼ºåŒ–å­¦ä¹ çš„ç»å…¸æ•™æï¼Œé‡ç‚¹ä»‹ç»å¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒç®—æ³•å’Œåº”ç”¨ã€‚

9. [ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‹ - åˆ˜å»ºå¹³](https://book.douban.com/subject/27030016/)  
   è¯¦ç»†è®²è§£äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬ç†è®ºã€å¸¸ç”¨ç®—æ³•ä»¥åŠåº”ç”¨ã€‚

10. [ã€ŠTensorFlow æ·±åº¦å­¦ä¹ ã€‹ - è®¤è¯ä½œè€…](https://www.packtpub.com/product/learn-tensorflow-2-0/9781800206025)  
    è¯¥ä¹¦è¯¦ç»†è®²è§£äº† TensorFlow æ¡†æ¶çš„ä½¿ç”¨æ–¹æ³•ï¼Œé€‚åˆå¸Œæœ›æŒæ¡ TensorFlow å¹¶åº”ç”¨äºå®é™…é¡¹ç›®çš„è¯»è€…ã€‚

11. [ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ - æèˆª](https://github.com/cszhangzhen/MachineLearning)  
    è¯¦ç»†ä»‹ç»äº†ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼Œé‡ç‚¹è®²è§£äº†æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ã€å†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œç­‰å¸¸ç”¨ç®—æ³•ã€‚

12. [ã€Šæœºå™¨å­¦ä¹ ã€‹ - å‘¨å¿—å](https://github.com/datawhalechina/leedl-tutorial)  
    ç³»ç»Ÿä»‹ç»æœºå™¨å­¦ä¹ çš„ä¸»è¦æ–¹æ³•ï¼ŒåŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ç­‰å†…å®¹ã€‚

13. [ã€Šè®¡ç®—æœºè§†è§‰ï¼šç®—æ³•ä¸åº”ç”¨ã€‹ - Richard Szeliski](http://szeliski.org/Book/)  
    ä»‹ç»è®¡ç®—æœºè§†è§‰çš„åŸºç¡€ç†è®ºå’Œå®é™…åº”ç”¨ï¼Œé€‚åˆè®¡ç®—æœºè§†è§‰ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…ã€‚

14. [ã€Šæ·±åº¦å­¦ä¹ ä¸è®¡ç®—æœºè§†è§‰ã€‹ - ææ²](https://zh.d2l.ai/chapter_computer-vision/index.html)  
    ä¸“æ³¨äºæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒç”Ÿæˆç­‰ã€‚

15. [ã€ŠHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlowã€‹ - AurÃ©lien GÃ©ron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032630/)  
    é€šè¿‡ Scikit-Learnã€Keras å’Œ TensorFlow å®ç°æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ï¼Œè¦†ç›–äº†å®é™…é¡¹ç›®ä¸­çš„å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‚

16. [ã€Šæ·±åº¦å­¦ä¹ ï¼šæ„å»ºç¥ç»ç½‘ç»œçš„è‰ºæœ¯ä¸ç§‘å­¦ã€‹ - è¿ˆå…‹å°”Â·å°¼å°”æ£®](https://www.nature.com/articles/167101)  
    æ·±å…¥æµ…å‡ºåœ°è®²è§£äº†ç¥ç»ç½‘ç»œçš„æ„å»ºå’Œè®­ç»ƒï¼Œé€‚åˆæœ‰ä¸€å®šåŸºç¡€çš„å­¦ä¹ è€…ã€‚

17. [ã€Šæ·±åº¦å­¦ä¹ å®æˆ˜ï¼šåŸºäºTensorFlowä¸Kerasã€‹ - æ¨é’](https://www.packtpub.com/product/learn-tensorflow-2-0/9781800206025)  
    æœ¬ä¹¦é€šè¿‡å¤§é‡å®ä¾‹ï¼Œæ·±å…¥è®²è§£äº†å¦‚ä½•ä½¿ç”¨ TensorFlow å’Œ Keras è¿›è¡Œæ·±åº¦å­¦ä¹ ã€‚

18. [ã€ŠData Science from Scratchã€‹ - Joel Grus](https://www.oreilly.com/library/view/data-science-from/9781492041139/)  
    ä»é›¶å¼€å§‹è®²è§£æ•°æ®ç§‘å­¦ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€å¯è§†åŒ–ã€æœºå™¨å­¦ä¹ ç­‰ã€‚

19. [ã€ŠPython for Data Analysisã€‹ - Wes McKinney](https://www.oreilly.com/library/view/python-for-data/9781491957660/)  
    é€šè¿‡ Python çš„ Pandas åº“è¿›è¡Œæ•°æ®åˆ†æï¼Œé€‚åˆæ•°æ®ç§‘å­¦é¢†åŸŸçš„åˆå­¦è€…å’Œä¸­çº§å­¦ä¹ è€…ã€‚

20. [ã€ŠMachine Learning Yearningã€‹ - Andrew Ng](https://www.deeplearning.ai/machine-learning-yearning/)  
    å´æ©è¾¾æ•™æˆçš„æœºå™¨å­¦ä¹ å®è·µæŒ‡å—ï¼Œé‡ç‚¹è®²è§£å¦‚ä½•æ­å»ºã€è°ƒä¼˜å’Œä¼˜åŒ–æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚

21. [ã€ŠHands-On Deep Learning with TensorFlowã€‹ - Dan Van Boxel](https://www.packtpub.com/product/hands-on-deep-learning-with-tensorflow/9781788621757)  
    é€šè¿‡ TensorFlow æ„å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å­¦ä¹ å¦‚ä½•è°ƒä¼˜å’Œéƒ¨ç½²ã€‚

22. [ã€ŠAI Superpowers: China, Silicon Valley, and the New World Orderã€‹ - Kai-Fu Lee](https://www.amazon.com/AI-Superpowers-Silicon-Valley-Order/dp/1328691804)  
    è®¨è®ºäººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•ï¼Œç‰¹åˆ«æ˜¯ä¸­å›½å’Œç¡…è°·çš„AIç«äº‰ã€‚

23. [ã€ŠDeep Reinforcement Learning Hands-Onã€‹ - Maxim Lapan](https://www.packtpub.com/product/deep-reinforcement-learning-hands-on/9781838984393)  
    é€šè¿‡å®è·µå­¦ä¹ æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼Œå†…å®¹æ¶µç›–æ·±åº¦ Q ç½‘ç»œï¼ˆDQNï¼‰ã€ç­–ç•¥æ¢¯åº¦ç­‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚

24. [Data Science from Scratch by Joel Grus](https://www.oreilly.com/library/view/data-science-from/9781492041139/)  
    ä»é›¶å¼€å§‹è®²è§£æ•°æ®ç§‘å­¦ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€å¯è§†åŒ–ã€æœºå™¨å­¦ä¹ ç­‰ã€‚

25. [Deep Learning for Computer Vision by Rajalingappaa Shanmugamani](https://www.packtpub.com/product/deep-learning-for-computer-vision/9781788621757)  
    æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨ï¼Œæ¶µç›–ä»å›¾åƒåˆ†ç±»åˆ°ç›®æ ‡æ£€æµ‹ç­‰å¤šä¸ªåº”ç”¨ã€‚

## [ğŸ“°ç»å…¸è®ºæ–‡](papers)

- [Attention is All You Need](https://arxiv.org/abs/1706.03762)

- [ResNet (Deep Residual Learning)](https://arxiv.org/abs/1512.03385)

- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)

### ğŸ”® é€šç”¨å¤§æ¨¡å‹ / åŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰
| è®ºæ–‡       | é“¾æ¥                                                                                                                              | å…³é”®è¯            |
| -------- | ------------------------------------------------------------------------------------------------------------------------------- | -------------- |
| GPT-4    | [GPT-4 Technical Report (2023)](https://arxiv.org/abs/2303.08774)                                                               | å¤§è¯­è¨€æ¨¡å‹          |
| LLaMA 2  | [LLaMA 2: Open Foundation and Fine-Tuned Chat Models (2023)](https://arxiv.org/abs/2307.09288)                                  | å¼€æºå¤§æ¨¡å‹          |
| Mistral  | [Mistral: Faster and Better (2023)](https://arxiv.org/abs/2310.06825)                                                           | é«˜æ•ˆ Transformer |
| Gemini   | [Gemini 1: Unlocking multimodal understanding (2023)](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) | å¤šæ¨¡æ€            |
| Claude 3 | [Anthropic Claude 3 Report (2024)](https://www.anthropic.com/index/claude-3)                                                    | å¤šæ¨¡æ€å¯¹è¯          |


### ğŸ§  è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰
| è®ºæ–‡          | é“¾æ¥                                                                                                                           | å…³é”®è¯             |
| ----------- | ---------------------------------------------------------------------------------------------------------------------------- | --------------- |
| BERT        | [BERT: Pre-training of Deep Bidirectional Transformers (2018)](https://arxiv.org/abs/1810.04805)                             | Transformer ç¼–ç å™¨ |
| T5          | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (2020)](https://arxiv.org/abs/1910.10683) | æ–‡æœ¬ç»Ÿä¸€æ¡†æ¶          |
| InstructGPT | [Training language models to follow instructions (2022)](https://arxiv.org/abs/2203.02155)                                   | RLHF            |
| LoRA        | [LoRA: Low-Rank Adaptation of Large Language Models (2021)](https://arxiv.org/abs/2106.09685)                                | å¾®è°ƒæ–¹æ³•            |


### ğŸ§‘â€ğŸ¨ è®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰
| è®ºæ–‡                 | é“¾æ¥                                                                                                | å…³é”®è¯     |
| ------------------ | ------------------------------------------------------------------------------------------------- | ------- |
| Vision Transformer | [An Image is Worth 16x16 Words (2020)](https://arxiv.org/abs/2010.11929)                          | ViT     |
| DINOv2             | [DINOv2 (2023)](https://arxiv.org/abs/2304.07193)                                                 | è‡ªç›‘ç£è§†è§‰æ¨¡å‹ |
| Segment Anything   | [Segment Anything (2023)](https://arxiv.org/abs/2304.02643)                                       | å›¾åƒåˆ†å‰²    |
| CLIP               | [CLIP: Learning Transferable Visual Models (2021)](https://arxiv.org/abs/2103.00020)              | å›¾æ–‡å¯¹é½    |
| DreamBooth         | [DreamBooth: Fine Tuning Text-to-Image Diffusion Models (2022)](https://arxiv.org/abs/2208.12242) | ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆ |

### ğŸ” å¤šæ¨¡æ€ï¼ˆå›¾æ–‡/è§†é¢‘/è¯­éŸ³ï¼‰
| è®ºæ–‡       | é“¾æ¥                                                                                              | å…³é”®è¯   |
| -------- | ----------------------------------------------------------------------------------------------- | ----- |
| Flamingo | [Flamingo: A Visual Language Model (2022)](https://arxiv.org/abs/2204.14198)                    | å›¾æ–‡é—®ç­”  |
| BLIP-2   | [BLIP-2: Bootstrapping Language-Image Pre-training (2023)](https://arxiv.org/abs/2301.12597)    | å›¾æ–‡ç”Ÿæˆ  |
| Whisper  | [Whisper: Robust Speech Recognition (2022)](https://openai.com/research/whisper)                | è¯­éŸ³è¯†åˆ«  |
| SpeechT5 | [SpeechT5: Unified-Modal Encoder-Decoder Pre-training (2022)](https://arxiv.org/abs/2110.07205) | å¤šè¯­ç§è¯­éŸ³ |

### ğŸ¤– å¼ºåŒ–å­¦ä¹  / è‡ªåŠ¨æ™ºèƒ½ä½“ï¼ˆAgentï¼‰
| è®ºæ–‡         | é“¾æ¥                                                                                             | å…³é”®è¯        |
| ---------- | ---------------------------------------------------------------------------------------------- | ---------- |
| AlphaGo    | [Mastering the game of Go (2016)](https://www.nature.com/articles/nature16961)                 | å¼ºåŒ–å­¦ä¹ ç»å…¸     |
| ReAct      | [ReAct: Synergizing Reasoning and Acting (2022)](https://arxiv.org/abs/2210.03629)             | è¯­è¨€æ¨¡å‹ Agent |
| AutoGPT    | [Auto-GPT (GitHub Repo)](https://github.com/Torantulino/Auto-GPT)                              | LLM è‡ªåŠ¨è§„åˆ’   |
| Voyager    | [Voyager: LLM-Powered Embodied Agent in Minecraft (2023)](https://voyager.minedojo.org/)       | æ¸¸æˆ AI      |
| OpenAgents | [OpenAgents: An Open Platform for LLM Agent Research (2024)](https://arxiv.org/abs/2404.13722) | å¤šä»»åŠ¡æ™ºèƒ½ä½“     |

### ğŸ“Š å‘é‡æ£€ç´¢ / å‘é‡æ•°æ®åº“ / Embedding
| è®ºæ–‡               | é“¾æ¥                                                                                     | å…³é”®è¯     |
| ---------------- | -------------------------------------------------------------------------------------- | ------- |
| FAISS            | [FAISS: Efficient Similarity Search (2017)](https://github.com/facebookresearch/faiss) | å‘é‡æ£€ç´¢åº“   |
| HNSW             | [HNSW: Efficient and Robust ANN (2018)](https://arxiv.org/abs/1603.09320)              | é«˜æ•ˆ ANN  |
| GTE              | [GTE: General Text Embeddings (2023)](https://huggingface.co/thenlper/gte-base)        | é€šç”¨æ–‡æœ¬å‘é‡  |
| OpenAI Embedding | [OpenAI Text Embeddings (2022)](https://platform.openai.com/docs/guides/embeddings)    | GPT å‘é‡åŒ– |




---

# ğŸ’– è‡´è°¢

- å¼€æºç¤¾åŒºæä¾›çš„ä¼˜ç§€å·¥å…·

- æ•™è‚²å…ˆé©±ï¼šç¤¾ä¼šå„ç•ŒAIå­¦è€…ï¼Œå´æ©è¾¾æ•™æˆç­‰æ•™è‚²å…ˆé©±

- æ‚¨ï¼æ¯ä¸€ä½ä½¿ç”¨å’Œä¼ æ’­èµ„æ–™çš„å­¦ä¹ è€…

> â€œäººå·¥æ™ºèƒ½å¦‚åŒæ–°æ—¶ä»£çš„ç”µåŠ›ï¼Œå°†é‡å¡‘æ‰€æœ‰è¡Œä¸šã€‚â€ â€” Andrew Ng  
> ğŸŒ± å¼€å¯ä½ çš„ AI å­¦ä¹ ä¹‹æ—…ï¼Œå°±ä»è¿™é‡Œå¼€å§‹ï¼
